---
title: "var-resample"
author: "Bj√∂rn Siepe"
date: "2022-11-10"
output: html_document
---

# Background

Goal is to compare if two VAR models $A$ and $B$ are really different from another. We use resampling to do this. \## Idea: 1. Fit $A$ and $B$ to their respective data. 2. Using parameters of $A$, generate $n$ new time series. 3. Refit $A$ and $B$ on each of the $n$ time series. 4. Obtain measure of fit, such as $MSE$. 5. Compare error distributions, either by cutoff or something like a Divergence. (6. Maybe repeat the other way around, so sampling from $B$?)

I use a developmental version of the BGGM package that returns the covariance matrix of residuals for each posterior sample. I need this to sample new data.
```{r preparations, include = FALSE}

library(tidyverse)
library(graphicalVAR)
library(doParallel)
library(mgm)
library(mlVAR)
# library(BGGM)
library("BGGM", lib.loc = "C:/Users/Bjoern/R-dev")
library(reshape2)      # Data manipulation
library(mvtnorm)       # Sim from posterior
library(stats)         # KS-Test
library(philentropy)   # divergence measures
library(todor)         # keep on track with stuff to do
source("aux_funs.R")
library(ggokabeito)
```



Dataset overview:
- l_raw: Contains `n_mod` datasets sampled from specific DGP.
- l_res: Contains `n_ind`fitted models, one for each l_raw. Represents different people under same DGP.  
- l_params: Contains posterior beta and kappa matrices for each fitted model in l_res.
- 

New data-generating processes by Hoekstra:
She used PDC and PCC instead of beta and kappa. Maybe I won't use her dgps after all. 
```{r}



```




```{r generate-graph}
# Ground truth model is still generated with graphicalVAR 
# could also use empirical data with varying sparsity
set.seed(2022)    # does NOT help here with model creation! need to write own function
og_graph <- randomGVARmodel(Nvar = 6, probKappaEdge = 0.5, probBetaEdge = 0.3)

beta <- as.matrix(read.table(header = FALSE, colClasses = "numeric", text = "
 0.2266407 0.0000000  0.0000000 -0.2668593  0.0000000 0.0000000
-0.7380388 0.2266407  0.0000000  0.0000000 -0.9288327 0.0000000
 0.0000000 0.0000000  0.2266407  0.9571318  0.2409225 0.5543485
 0.0000000 0.0000000  0.0000000  0.2266407 -0.7438448 0.0000000
 0.5214148 0.0000000  0.0000000  0.0000000  0.2266407 0.0000000
 0.0000000 0.0000000 -0.8903007  0.0000000  0.0000000 0.2266407"))

kappa <- as.matrix(read.table(header = FALSE, colClasses = "numeric", text = "
 1.0000000  0.0000000  0.0000000 0.0000000  0.4018933 0.3717013
 0.0000000  1.0000000  0.2266407 0.5527593 -0.2654634 0.2593779
 0.0000000  0.2266407  1.0000000 0.0000000 -0.3318945 0.3175423
 0.0000000  0.5527593  0.0000000 1.0000000  0.0000000 0.0000000
 0.4018933 -0.2654634 -0.3318945 0.0000000  1.0000000 0.0000000
 0.3717013  0.2593779  0.3175423 0.0000000  0.0000000 1.0000000"))

# compute partial correlations from kappa
# in the case of only 1s on the diagonal of kappa, this just changes the sign
pcc <- -cov2cor(kappa)


graph <- list()
graph$beta <- beta
graph$kappa <- kappa
graph$PCC <- pcc
diag(graph$PCC) <- rep(0,6)
dimnames(graph$beta) <- NULL
dimnames(graph$kappa) <- NULL



# # # add slight change of one model parameter to the list
# graph2 <- graph
# graph2$beta[which.max(graph2$beta)] <- graph2$beta[which.max(graph2$beta)]*1.5
# graph2$beta[which.max(graph2$kappa)] <- graph2$beta[which.max(graph2$kappa)]*1.5
# 
# l_graph <- list(graph = graph,
#                 graph2 = graph2)


# # add stronger change of one model parameter
# graph2 <- graph
# graph2$beta[which.max(graph2$beta)] <- graph2$beta[which.max(graph2$beta)]*-1
#   
# l_graph <- list(graph = graph, 
#                 graph2 = graph2)


# # # also change kappa but less strongly
# graph2 <- graph
# graph2$beta[which.max(graph2$beta)] <- graph2$beta[which.max(graph2$beta)]*1.8
# graph2$kappa[which.max(graph2$kappa)] <- graph2$kappa[which.max(graph2$kappa)]*1.8
# 
# 
# l_graph <- list(graph = graph,
#                 graph2 = graph2)



# also change kappa
# TODO Need to be careful here! Kappa may not be >1, maybe not even 1 (I have to partial other stuff out...)
# 
# graph2 <- graph
# graph2$beta[which.max(graph2$beta)] <- graph2$beta[which.max(graph2$beta)]*2
# graph2$kappa <- changemax_kappa(graph2$kappa, change = 2)

# Add random noise to the network
graph2 <- graph
graph2$beta <- graph2$beta + runif(36, -0.05, 0.05)
graph2$kappa <- graph2$kappa + runif(36, -0.05, 0.05)
diag(graph2$kappa) <- c(1,1,1,1,1,1)
graph2$kappa <- Matrix::forceSymmetric(graph2$kappa)




l_graph <- list(graph = graph,
                graph2 = graph2)



# Idea for the future: don't simulate (50, 100, 300, 500) observations,
# but just simulate 500 and then subsample from it. Then datasets are matched.
# # maybe DON'T DO THIS! If I standardize these data again when estimating a VAR
# # model, the data changes. 



```


```{r generate-rawdata}
# Storage
l_raw <- list()

# Simulation conditions
n_ind <- 100   # number of individuals (so models to create)
n_tp <- 75     # number of timepoints per time series
n_postds <- 100     # number of posterior datasets to create 



# Think about if I actually need to standardize here
# because everything will be standardized by var_estimate anway

ncores = parallel::detectCores() - 4
cl = makeCluster(ncores)
registerDoParallel(cl)


l_raw$graph <- sim_raw_parallel(dgp = graph, n = n_ind, 
                                tp = n_tp, means = 0,
                                standardize = TRUE)
l_raw$graph2 <- sim_raw_parallel(dgp = graph2, n = n_ind, 
                                 tp = n_tp, means = 0,
                                 standardize = TRUE)

stopCluster(cl)
```


# Bayesian approach

Idea: Use the posterior distribution to obtain a variance-covariance matrix of the parameters, then sample 100 different datasets from these parameters?

```{r estimate-models}
# Bayesian model parameters
rho_sd <- 0.5
beta_sd <- 1
seed <- 2022
n_iter <- 5000

# # Excluded for speed:

l_res <- list()
l_res2 <- list()
ncores = parallel::detectCores() - 2
cl = makeCluster(ncores)
registerDoParallel(cl)

l_res <- fit_var_parallel(data = l_raw$graph, n = n_ind,
                 rho_prior = rho_sd, beta_prior = beta_sd, seed = seed,
                 iterations = n_iter)


l_res2 <- fit_var_parallel(data = l_raw$graph2, n = n_ind,
                 rho_prior = rho_sd, beta_prior = beta_sd, seed = seed,
                 iterations = n_iter)

stopCluster(cl)

# write_rds(l_res, "l_res.Rds")
# l_res <- read_rds("l_res.Rds")
# write_rds(l_res2, "l_res2.Rds")
# l_res2 <- read_rds("l_res2.Rds")
```

Comparison of results with grahpicalVAR is done in another script ("bggm-var-investigation.Rmd"). Here, we look at how well our model recovered the correct parameters. 
```{r recovery}
rec_res <- compare_dgp(graph, est_bggm = l_res, comp_gvar = FALSE, est_gvar = NULL)


```







## Directly use posterior samples

Take the first 100 samples from the posterior of the first model (after deleting warmup samples).
```{r simulate-from-posterior}

# Excluded for speed

# # setup foreach for data generation
ncores = parallel::detectCores() - 4
cl = makeCluster(ncores)
registerDoParallel(cl)

l_data <- list()
l_data <- sim_from_post_parallel(fitobj = l_res, n = n_ind, n_datasets = n_postds, tp = n_tp,
                       iterations = n_iter, means = 0, convert_bggm = FALSE)


stopCluster(cl)


# # second dgp
ncores = parallel::detectCores() - 4
cl = makeCluster(ncores)
registerDoParallel(cl)

l_data2 <- list()
l_data2 <- sim_from_post_parallel(fitobj = l_res2, n = n_ind, n_datasets = n_postds, tp = n_tp,
                       iterations = n_iter, means = 0, convert_bggm = FALSE)


stopCluster(cl)


# write_rds(l_data, "l_data.Rds")
# write_rds(l_data2, "l_data2.Rds")

# l_data <- read_rds("l_data.Rds")
# l_data2 <- read_rds("l_data2.Rds")

# TODO: maybe use own function to simulateVAR model, this gives me weird results
# Could also use sth. inspired by here: https://github.com/jmbh/ARVAR/blob/master/aux_functions.R

# DO I HAVE TO TRANSPOSE THE BETA MATRIX HERE?!?!?!
# DIFFERENT FORMAT IN BGGM and graphicalVAR
# put 1 on diagonal of matrix

# IMPORTANT! KAPPA IS NOT EQUAL TO PCOR MATRIX. KAPPA = PRECISION MATRIX


```

## Frobenius Norm Approach
Another idea: Compute Frobenius norm between models on resampled datasets compared to reference model and then compare to actual difference between two models. 

```{r same-dgp}
# Fit the model to posterior data samples
rho_sd <- 0.5
beta_sd <- 1
seed <- 2022
n_iter <- 5000

# # Same DGP
ncores = parallel::detectCores() - 4
cl = makeCluster(ncores)
registerDoParallel(cl)
l_postres <- list()

before <- Sys.time()

l_postres <- lapply(l_data, function(x) fit_var_parallel(data = x, n = 100,
                 rho_prior = rho_sd, beta_prior = beta_sd, seed = seed,
                 iterations = n_iter, posteriorsamples = TRUE, pruneresults = TRUE) )
after <- before - Sys.time()
stopCluster(cl)
# 
# write_rds(l_postres, "l_postres.Rds")
# l_postres <- read_rds("l_postres.Rds")



# Compare all possible combinations
comp_combinations <- expand_grid_unique(mod_a = seq(1, n_ind, 1),
                                 mod_b = seq(1, n_ind, 1))

comp_conditions <- data.frame(mod_a = rep(comp_combinations[,1], 3),
                        mod_b = rep(comp_combinations[,2], 3),
                        fitpost_a = rep("l_postres", nrow(comp_combinations)*3),
                        fitpost_b = rep("l_postres", nrow(comp_combinations)*3), 
                        fitemp_a = rep("l_res", nrow(comp_combinations)*3),
                        fitemp_b = rep("l_res", nrow(comp_combinations)*3),
                        n_datasets = rep(n_postds, nrow(comp_combinations)*3),
                        comparison = c(rep("frob", nrow(comp_combinations)), 
                                       rep("maxdiff", nrow(comp_combinations)),
                                       rep("l1", nrow(comp_combinations))))

ncores = parallel::detectCores() - 4
cl = makeCluster(ncores)
registerDoParallel(cl)
starttime <- Sys.time()
cross_compare_res <- list()
cross_compare_res <- 
  lapply(c(1:nrow(comp_conditions)), function(i){
    args <- comp_conditions[i,]
    cross_compare_emp(
      mod_a = args$mod_a, 
      mod_b = args$mod_b,
      fitpost_a = eval(as.name(paste(args$fitpost_a))),
      fitpost_b = eval(as.name(paste(args$fitpost_b))), 
      fitemp_a = eval(as.name(paste(args$fitemp_a))), 
      fitemp_b = eval(as.name(paste(args$fitemp_b))), 
      n_datasets = args$n_datasets, 
      comparison = args$comparison
    )
    }
  )


stoptime <- Sys.time()-starttime    # ~16 seconds for 4950 comparisons!
stopCluster(cl)

# TODO right now I do not take into account that some samples did not work
# need to implement this, maybe as a counter


eval_res <- lapply(cross_compare_res, cross_compare_eval)
df_eval_res <- as.data.frame(do.call(rbind, eval_res))
df_eval_res %>% 
  mutate(beta_a = as.numeric(beta_a),
         beta_b = as.numeric(beta_b),
         pcor_a = as.numeric(pcor_a),
         pcor_b = as.numeric(pcor_b),
         comp = as.factor(as.character(comp))) %>% 
  group_by(comp) %>% 
  # number of tries per condition
  add_count(comp) %>% 
  summarize(sig_beta = sum(beta_a < 5 & beta_b < 5)/n,
            sig_pcor = sum(pcor_a < 5 & pcor_b < 5)/n) %>% 
  ungroup() %>% 
  distinct(comp, sig_beta, sig_pcor)








plot_test_samedgp75 <- df_eval_res %>% 
  pivot_longer(cols = c(beta_a, beta_b, pcor_a, pcor_b), names_to = "res") %>% 
  mutate(value = as.numeric(value),
         comp = as.character(comp)) %>% 
  ggplot(aes(x = value, color = comp, fill = comp))+
  geom_histogram(bins = 100)+
  theme_minimal()+
  scale_fill_okabe_ito()+
  scale_color_okabe_ito()+
  labs(title = "Count of posterior differences larger than empirical",
       subtitle = "Simulating from same DGP",
       caption = "75 Timepoints, 100 Individuals")+
  facet_wrap(~comp)+
  theme(legend.position = "none")
ggsave("figures/plot_test_samedgp75.svg", plot_test_samedgp75,  device = "svg",
       height = 12, width = 16, units = "cm")

```


```{r different-dgp}
# # Another DGP
ncores = parallel::detectCores() - 4
cl = makeCluster(ncores)
registerDoParallel(cl)
l_postres2 <- list()

before <- Sys.time()

l_postres2 <- lapply(l_data2, function(x) fit_var_parallel(data = x, n = 100,
                 rho_prior = rho_sd, beta_prior = beta_sd, seed = seed,
                 iterations = n_iter, posteriorsamples = TRUE, pruneresults = TRUE) )
after <- before - Sys.time()
stopCluster(cl)
# l_postres2 <- read_rds("l_postres2.Rds")




# Compare all possible combinations
comp_combinations2 <- expand_grid_unique(mod_a = seq(1, n_ind, 1),
                                 mod_b = seq(1, n_ind, 1))

comp_conditions2 <- data.frame(mod_a = rep(comp_combinations2[,1], 3),
                        mod_b = rep(comp_combinations2[,2], 3),
                        fitpost_a = rep("l_postres", nrow(comp_combinations2)*3),
                        fitpost_b = rep("l_postres2", nrow(comp_combinations2)*3), 
                        fitemp_a = rep("l_res", nrow(comp_combinations2)*3),
                        fitemp_b = rep("l_res2", nrow(comp_combinations2)*3),
                        n_datasets = rep(n_postds, nrow(comp_combinations2)*3),
                        comparison = c(rep("frob", nrow(comp_combinations2)), 
                                       rep("maxdiff", nrow(comp_combinations2)),
                                       rep("l1", nrow(comp_combinations2))))

ncores = parallel::detectCores() - 4
cl = makeCluster(ncores)
registerDoParallel(cl)
starttime <- Sys.time()
cross_compare_res2 <- list()
cross_compare_res2 <- 
  lapply(c(1:nrow(comp_conditions2)), function(i){
    args <- comp_conditions2[i,]
    cross_compare_emp(
      mod_a = args$mod_a, 
      mod_b = args$mod_b,
      fitpost_a = eval(as.name(paste(args$fitpost_a))),
      fitpost_b = eval(as.name(paste(args$fitpost_b))), 
      fitemp_a = eval(as.name(paste(args$fitemp_a))), 
      fitemp_b = eval(as.name(paste(args$fitemp_b))), 
      n_datasets = args$n_datasets, 
      comparison = args$comparison
    )
    }
  )


stoptime <- Sys.time()-starttime    # ~16 seconds for 4950 comparisons!
stopCluster(cl)




# Build plot separated by PCOR and BETA and by comparison type
eval_res2 <- lapply(cross_compare_res2, cross_compare_eval)
df_eval_res2 <- as.data.frame(do.call(rbind, eval_res2))
plot_test_comp2 <- df_eval_res2 %>% 
  pivot_longer(cols = -comp, 
               names_to = c("matrix", ".value"),
               names_sep = "_") %>% 
  pivot_longer(cols = c(a,b), values_to = "value", names_to = "ref_model") %>% 
  mutate(value = as.numeric(value),
         comp = as.character(comp)) %>% 
  ggplot(aes(x = value, color = comp, fill = comp))+
  geom_histogram(bins = 100, alpha =0.8)+
  theme_minimal()+
  scale_fill_okabe_ito()+
  scale_color_okabe_ito()+
  labs(title = "Count of posterior differences larger than empirical",
       subtitle = "Simulating from different DGP (random uniform noise [-0.05, 0.05])",
       caption = "75 Timepoints, 100 Individuals")+
  facet_grid(comp~matrix)

ggsave("figures/plot_test_runifnoise75.svg", plot_test_comp2,  device = "svg",
       height = 12, width = 16, units = "cm")
```






















