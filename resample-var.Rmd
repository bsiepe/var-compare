---
title: "var-resample"
author: "Bj√∂rn Siepe"
date: "2022-11-10"
output: html_document
---

# Background


```{r preparations, include = FALSE}
library(tidyverse)
library(graphicalVAR)
library(doParallel)
library(doRNG)         # reproducibility for parallelization
library(mgm)
library(mlVAR)
library(BGGM)
# library("BGGM", lib.loc = "C:/Users/Bjoern/R-dev")
library(reshape2)      # Data manipulation
library(mvtnorm)       # Sim from posterior
library(stats)         # KS-Test
# library(philentropy)   # divergence measures
# library(todor)         # keep on track with stuff to do
source("aux_funs.R")
# library(ggokabeito)
library(Matrix)
library(here)
library(rrapply)       # deeply nested list
library(ggh4x)
here::i_am("var-compare.Rproj")


seed = 2022
set.seed(seed)
```



Dataset overview:
- l_raw: Contains `n_mod` datasets sampled from specific DGP.
- l_res: Contains `n_ind`fitted models, one for each l_raw. Represents different people under same DGP.  
- l_params: Contains posterior beta and kappa matrices for each fitted model in l_res.
- 

New data-generating processes by Hoekstra:
She used PDC and PCC instead of beta and kappa. Maybe I won't use her dgps after all. 
For now, pretend that she used beta and kappa, so we likely use a bit sparser graphs than she did.
```{r dgp-hoekstra}
```


```{r dgp-fried}
fried_net <- readRDS(here("data/graph_fried.Rds"))

graph_fried <- list()
graph_fried$beta <- fried_net$beta
graph_fried$kappa <- fried_net$kappa

# For now, delete 3 edges so that every dgp has 6 vars
graph_fried$beta <- graph_fried$beta[1:6, 1:6]
graph_fried$kappa <- graph_fried$kappa[1:6, 1:6]
```


```{r own-graph}
graph <- readRDS(here::here("data/graph.RDS"))

# delete PCC (not needed)
graph <- graph[-3]


```

Graph with non-sparsity
```{r}
graph_full_f <- readRDS("full_graph.RDS")

graph_full <- list(
  beta = graph_full_f$beta_mu,
  kappa = graph_full_f$kappa_mu
)
# Non-symmetric Kappa due to rounding errors
graph_full$kappa <- as.matrix(Matrix::forceSymmetric(graph_full$kappa))

```

Chain Graph Hoekstra
```{r}
graph_hoekstra_6node <- readRDS(here::here("data/hoekstra_synth_6node.RDS"))


```

Synthetic non-sparse graph
```{r}
graph5 <- readRDS(here::here("data/graph5.RDS"))

```





## Change Graphs
Now we can change all graphs according to the simulation conditions.
```{r change-graphs}
# Store graphs as list
# l_graphs <- list(graph1 = graph,
#                  graph2 = graph_full, 
#                  graph3 = graph_fried,
#                  graph4 = graph_hoekstra_6node,
#                  graph5 = graph5)

l_graphs <- readRDS("data/l_graphs.RDS")
l_changed_graphs <-readRDS("data/l_changed_graphs.RDS")

# Apply change function to every graph
l_changed_graphs <- lapply(l_graphs,
                           function(x) {change_graphs(
                                            truegraph = x,
                                            changemax = c(1.2, 1.4, 1.6),
                                            noise = c(0.1,0.2,0.3),
                                            permute_active = FALSE,
                                            seed = seed)})

# again for graph5 
l_change5 <- change_graphs(truegraph = l_graphs$graph5,
                           changemax = c(1.2, 1.4, 1.6),
                                            noise = c(0.1,0.2,0.3),
                                            permute_active = FALSE,
                                            seed = 2023)

l_changed_graphs$graph5$noise0.2 <- l_change5$noise0.2


# write_rds(l_changed_graphs, "data/l_changed_graphs.RDS")
# write_rds(l_graphs, "data/l_graphs.RDS")

```

New idea: create change matrices manually. 
```{r}
# l_noise <- list()
# l_noise$noise1 <- round(matrix(runif(6*6, min = -.1, max = .1), nrow = 6, ncol = 6),3)
# l_noise$noise2 <- round(matrix(runif(6*6, min = -.2, max = .2), nrow = 6, ncol = 6),3)
# l_noise$noise3 <- round(matrix(runif(6*6, min = -.3, max = .3), nrow = 6, ncol = 6),3)
# 
# lapply(l_noise, function(x) mean(abs(x)))



```




## Simulate Raw Data
Then, generate rawdata from data-generating processes. We create more posterior datasets than we fit in the end, because some of them may not converge when using the posterior predictive approach. 

```{r generate-rawdata-parallel}

# Simulation conditions
n_ind <- 100 # number of individuals(so models to create) 
n_tp <- c(50,100,200,400, 1000) # number of timepoints
n_postds <- 120 # number of posterior datasets
seed <- 2022




# Think  if I actually need to standardize here
# because everything will be standardized by var_estimate anyway


# Changed: instead of n_ind, we create n_postds datasets 
# because some models don't converge
before_simraw <- Sys.time()
ncores = 40
cl = makeCluster(ncores)
registerDoParallel(cl)
# l_raw <- list()
# l_raw$graph5 <- l_raw$graph4 <- l_raw$graph3 <- l_raw$graph2 <- l_raw$graph1 <-  list()
for(t in seq_along(n_tp)){
  # l_raw$graph1[[t]] <- list()
  # l_raw$graph1[[t]] <- lapply(l_changed_graphs$graph1,
  #                                 function(x) {sim_raw_parallel(
  #                                   dgp = x,
  #                                   n = n_postds,
  #                                   tp = n_tp[t],
  #                                   seed = seed,
  #                                   means = 0,
  #                                   standardize = TRUE)})
  # 
  # l_raw$graph2[[t]] <- list()
  # l_raw$graph2[[t]] <- lapply(l_changed_graphs$graph1,
  #                                 function(x) {sim_raw_parallel(
  #                                   dgp = x,
  #                                   n = n_postds,
  #                                   tp = n_tp[t],
  #                                   seed = seed,
  #                                   means = 0,
  #                                   standardize = TRUE)})
  # l_raw$graph3[[t]] <- list()
  # l_raw$graph3[[t]] <- lapply(l_changed_graphs$graph3, 
  #                                 function(x) {sim_raw_parallel(
  #                                   dgp = x, 
  #                                   n = n_postds, 
  #                                   tp = n_tp[t], 
  #                                   seed = seed,
  #                                   means = 0,
  #                                   standardize = TRUE)})
  # l_raw$graph4[[t]] <- list()
  # l_raw$graph4[[t]] <- lapply(l_changed_graphs$graph4, 
  #                                 function(x) {sim_raw_parallel(
  #                                   dgp = x, 
  #                                   n = n_postds, 
  #                                   tp = n_tp[t], 
  #                                   seed = seed,
  #                                   means = 0,
  #                                   standardize = TRUE)})
  # l_raw$graph5[[t]] <- lapply(l_changed_graphs$graph5, 
  #                                 function(x) {sim_raw_parallel(
  #                                   dgp = x, 
  #                                   n = n_postds, 
  #                                   tp = n_tp[t], 
  #                                   seed = seed,
  #                                   means = 0,
  #                                   standardize = TRUE)})
  l_raw$graph5[[t]]$noise0.2 <- sim_raw_parallel(dgp = l_changed_graphs$graph5$noise0.2,
                                                 n = n_postds, 
                                                 tp = n_tp[t],
                                                 seed = seed,
                                                 means = 0, 
                                                 standardize = TRUE)
  
  
}

stopCluster(cl)

after_simraw <- Sys.time()-before_simraw  # less than 4 minutes

# write_rds(l_raw, "data/l_raw_new_1703.RDS")
l_raw <- readRDS(here::here("data/l_raw_new_1703.RDS"))


```


### Raw data permutation
As a new change condition, just change variable indexes in the data before fitting. 
```{r}
for(t in seq_along(n_tp)){
  l_raw$graph1[[t]]
  l_raw$graph1[[t]]$permute <- lapply(l_raw$graph1[[t]]$truegraph,
                                  function(x) {
                                    x$data <- x$data[,c(1,3,4,2,5,6)]
                                    x$args$dgp <- "permute134256" 
                                    x
                                  })

  l_raw$graph2[[t]]$permute <- lapply(l_raw$graph2[[t]]$truegraph,
                                  function(x) {
                                    x$data <- x$data[,c(1,3,4,2,5,6)]
                                    x$args$dgp <- "permute134256" 
                                    x
                                  })

  l_raw$graph3[[t]]$permute <- lapply(l_raw$graph3[[t]]$truegraph,
                                  function(x) {
                                    x$data <- x$data[,c(1,3,4,2,5,6)]
                                    x$args$dgp <- "permute134256" 
                                    x
                                  })
  l_raw$graph4[[t]]$permute <- lapply(l_raw$graph4[[t]]$truegraph,
                                  function(x) {
                                    x$data <- x$data[,c(1,3,4,2,5,6)]
                                    x$args$dgp <- "permute134256" 
                                    x
                                  })
  l_raw$graph5[[t]]$permute <- lapply(l_raw$graph4[[t]]$truegraph,
                                  function(x) {
                                    x$data <- x$data[,c(1,3,4,2,5,6)]
                                    x$args$dgp <- "permute134256" 
                                    x
                                  })
  
}




```






# Bayesian approach
Fit a VAR model to each raw dataset. 
```{r}
# model parameters
rho_sd <- 0.5      # Prior for partial correlations
beta_sd <- 1       # Prior for regression matrix
seed <- 2022
n_iter <- 50000

# second iteration with more narrow priors
rho_sd <- 0.25      # Prior for partial correlations
beta_sd <- 0.2       # Prior for regression matrix
seed <- 2022
n_iter <- 50000


# Prior switch
prior_wide <- FALSE
ifelse(prior_wide, 
       {
         rho_sd <- 0.5
         beta_sd <- 1
       },
       {
         rho_sd <- 0.25
         beta_sd <- 0.2
       })



before_fitraw <- Sys.time()
ncores = 50
cl = makeCluster(ncores)
registerDoParallel(cl)
clusterExport(cl, c("fit_var_parallel_merged", "summarize_post"))

# Only compute for specific modification 
# l_raw <- lapply(l_raw, function(x) lapply(x, function(y) list(noise0.2 = y$noise0.2)))

dgp_names <- c("graph1", "graph2", "graph3", "graph4", "graph5")
dgp_names <- c("graph3", "graph4", "graph5")
  
for(t in seq_along(n_tp)){
  for(dgp in dgp_names){
    
    # output label based on prior
    dgp_string <- ifelse(prior_wide, dgp, paste0("narrow_",dgp))
    
    lapply(l_raw[[dgp]][[t]], function(x){fit_var_parallel_merged(
    data = x, n = n_ind, nds = n_postds, rho_prior = rho_sd, beta_prior = beta_sd, seed = seed, iterations = n_iter, get_kappa = FALSE, summarize_post = FALSE,      pruneresults = FALSE, dgp_name = dgp_string, save_files = TRUE
  )})
  }
}
stopCluster(cl)
after_fitraw <- Sys.time()-before_fitraw


```


OLD: 
```{r}
for(t in seq_along(n_tp)){
    lapply(l_raw$graph1[[t]], function(x){fit_var_parallel_merged(
    data = x, n = n_ind, nds = n_postds, rho_prior = rho_sd, beta_prior = beta_sd, seed = seed, iterations = n_iter, get_kappa = FALSE, summarize_post = FALSE,
    pruneresults = FALSE, dgp_name = "graph1", save_files = TRUE
  )})
    lapply(l_raw$graph2[[t]], function(x){fit_var_parallel_merged(
    data = x, n = n_ind, nds = n_postds, rho_prior = rho_sd, beta_prior = beta_sd, seed = seed, iterations = n_iter, get_kappa = FALSE, summarize_post = FALSE,
    pruneresults = FALSE, dgp_name = "graph2", save_files = TRUE
  )})
    lapply(l_raw$graph3[[t]], function(x){fit_var_parallel_merged(
    data = x, n = n_ind, nds = n_postds, rho_prior = rho_sd, beta_prior = beta_sd, seed = seed, iterations = n_iter, get_kappa = FALSE, summarize_post = FALSE,
    pruneresults = FALSE, dgp_name = "graph3", save_files = TRUE
  )})
    lapply(l_raw$graph4[[t]], function(x){fit_var_parallel_merged(
    data = x, n = n_ind, nds = n_postds, rho_prior = rho_sd, beta_prior = beta_sd, seed = seed, iterations = n_iter, get_kappa = FALSE, summarize_post = FALSE,
    pruneresults = FALSE, dgp_name = "graph4", save_files = TRUE
  )})
    lapply(l_raw$graph5[[t]], function(x){fit_var_parallel_merged(
  data = x, n = n_ind, nds = n_postds, rho_prior = rho_sd, beta_prior = beta_sd, seed = seed, iterations = n_iter, get_kappa = FALSE, summarize_post = FALSE,
  pruneresults = FALSE, dgp_name = "graph5", save_files = TRUE
  )})

}
```



For the server: move some files to HDD
```{r}
l_copy <- list.files(path = here::here("data/compare_sim_fits"), pattern = "graph5")
file.copy(from = paste0(here::here("data/compare_sim_fits/"), l_copy),
          to = paste0("/home/bjoern/HDD/var-compare/data/", l_copy))


file.remove(from = paste0(here::here("data/compare_sim_fits/"), l_copy))

```




# New Approach (25.01.2023): Posterior Comparison without Predictive

Compare all models:
```{r}
# Setup list of conditions
# All possible model combinations
comp_combinations <- expand_grid_unique(mod_a = seq(1, n_ind, 1),
                                 mod_b = seq(1, n_ind, 1))
# number of data-generating processes
n_dgp <- 5
# Number of comparison types
n_c_types <- 3

# Number of different graph structures
n_g_types <- 7

# Number of different tp conditions
n_t_types <- 5

dgp_names <- c("graph1", "graph2", "graph3", "graph4", "graph5")
dgp_names <- c("narrow_graph3", "narrow_graph4", "narrow_graph5")

# change_names <- c("truegraph", "change1.2", "change1.4", "change1.6",
#                   "noise0.1", "noise0.2", "noise0.3")
change_names <- c("truegraph", "change1.4", "change1.6",
                  "noise0.1", "noise0.2", "noise0.3", "permute134256")

comp_names <- c("frob","maxdiff", "l1")

comp_grid_mod <- expand.grid(mod_a = seq(1, n_ind, 1),
            mod_b = seq(1, n_ind, 1),
            dgp = dgp_names, 
            change = change_names,
            tp = n_tp,
            comp = comp_names)

# Filter redundant comparisons within truegraph
comp_grid_mod <- comp_grid_mod %>% 
  filter(!c(mod_a == mod_b & change == "truegraph")) 


# Number of comparison combinations
n_c_comb <- nrow(comp_grid_mod)

```


## Compare models 
Previous model objects became too large, now we read them in instead of keeping them in memory.
```{r}
comp_grid <- expand.grid(dgp = dgp_names, 
                         change = change_names, 
                         comp = comp_names,
                         tp = n_tp)
  
# Add filenames
comp_grid <- comp_grid %>% 
  mutate(ref_file = paste0("fit_", dgp, "_","truegraph","_",tp,".RDS"),
         comp_file = paste0("fit_", dgp, "_",change,"_",tp,".RDS"))


# Add filenames
comp_grid <- comp_grid %>% 
  mutate(ref_file = paste0("fit_", dgp, "_","truegraph","_",tp,".RDS"),
         comp_file = paste0("fit_", dgp, "_",change,"_",tp,".RDS"))


############################# NOT MORE THAN 3!!!!!!!!!!!!
before_comp <- Sys.time()
ncores <- 3
cl <- makeCluster(ncores)
clusterExport(cl, c("comp_grid",  "comp_grid_mod", "within_compare", "within_compare_eval", "post_distance_within", "here", "todo_files_num"))
clusterEvalQ(cl, library(tidyverse))

# todo change back to 1:nrow(comp_grid)
parLapply(cl = cl, 1:nrow(comp_grid), function(n){
  ## Get filter args
  dgp_it <- as.character(comp_grid$dgp[n])
  change_it <- as.character(comp_grid$change[n])
  tp_it <- as.numeric(as.character(comp_grid$tp[n]))
  comp_it <- as.character(comp_grid$comp[n])
  
  
  
  ## Read files
    l_ref <- readRDS(file = here::here(paste0("data/compare_sim_fits/", comp_grid$ref_file[n])))
    l_comp <- readRDS(file = here::here(paste0("data/compare_sim_fits/", comp_grid$comp_file[n])))
    
    


  ## Perform comparison 
  # Loop over all possible model combinations
  comp_ind <- comp_grid_mod %>% 
    mutate(dgp = as.character(dgp),
           change = as.character(change),
           tp = as.numeric(as.character(tp)),
           comp = as.character(comp)) %>% 
    filter(dgp == dgp_it &
           change == change_it &
           tp == tp_it &
           comp == comp_it)
  

  wc_res <- list()
  wc_res  <- lapply(c(1:nrow(comp_ind)), function(x){
    
    ## Get fitting args
    ma <- as.numeric(as.character(comp_ind$mod_a[x]))
    mb <- as.numeric(as.character(comp_ind$mod_b[x]))
    cmp <- as.character(comp_ind$comp[x])
    
    wc_res[[x]] <- list()
    wc_res[[x]] <- tryCatch({within_compare(mod_a = ma,
                      mod_b = mb,
                      fitpost_a = l_ref,
                      fitpost_b = l_comp,
                      fitemp_a = l_ref,
                      fitemp_b = l_comp,
                      n_datasets = 100,
                      n_draws = 1000,
                      comparison = cmp,
                      postpred = FALSE)}, error = function(e) NA)
  })
  
  # Save output
  saveRDS(wc_res, file = here::here(paste0("data/compare_sim_res/comp_",dgp_it, "_",change_it,"_", tp_it, "_",comp_it, ".RDS")))
  # print(paste0("Just finished row", n))
  
})

stopCluster(cl)
after_comp <- Sys.time()-before_comp



# Afterwards check if all combinations that should be there are indeed there! i.e. if all relevant files are present
exist_files <- list.files(path = here::here("data/compare_sim_res"))

desired_files <- vector(length = nrow(comp_grid))
desired_files <- data.frame(filename = rep(NA, nrow(comp_grid)),
                            rownum = seq(1,nrow(comp_grid), by = 1))
# desired_files <- list()
for(n in 1:nrow(comp_grid)){

  dgp_it <- as.character(comp_grid$dgp[n])
  change_it <- as.character(comp_grid$change[n])
  tp_it <- as.numeric(as.character(comp_grid$tp[n]))
  comp_it <- as.character(comp_grid$comp[n])
  
  desired_files[n,1]<- paste0("comp_", dgp_it, "_",change_it,"_", tp_it, "_",comp_it, ".RDS")
}
# Find files that were not created yet
todo_files <- setdiff(desired_files$filename, exist_files)
todo_files_num <- desired_files %>% 
  filter(!filename %in% exist_files) %>% 
  pull(rownum)
todo_files_num
# This then has to be passed back to the loop above

# Delete graph4 change1.2 for now
todo_files <- todo_files[-grep("graph1", todo_files)]

todo_files_num <- desired_files %>% 
  filter(!filename %in% exist_files) %>% 
  filter(!grepl("graph5_noise0.2", filename)) %>% 
  pull(rownum)

todo_files <- todo_files[grep("graph5", todo_files)]
todo_files_num <- desired_files %>% 
  filter(!filename %in% exist_files) %>% 
  filter(grepl("graph5", filename)) %>% 
  pull(rownum)

# Redo graph5_noise0.2
todo_files_num <- desired_files %>% 
  filter(str_detect(filename, "graph5_noise0.2")) %>% 
  pull(rownum)



```


For server: Moving files to HDD
```{r}
l_copy <- list.files(path = here::here("data/compare_sim_res"), pattern = "comp_graph5")
file.copy(from = paste0(here::here("data/compare_sim_res/"), l_copy),
          to = paste0("/home/bjoern/HDD/var-compare/data/compare_sim_res/", l_copy))

# NOTE - some files are accidentally called "compare_sim_rescomp..."


file.remove(from = paste0(here::here("data/compare_sim_res/"), l_copy))

```






Reading the files in again and extracting summary information for each
```{r}
file_list <- list.files(path = here::here("data/compare_sim_res"))


time_before_within_eval <- Sys.time()
# DONT GO TOO HIGH HERE!!!! FILES BECOME TOO LARGE
ncores = 3
cl = makeCluster(ncores)
registerDoParallel(cl)
l_comp_res <- list()
l_comp_res <- foreach(i = 1:length(file_list)) %dopar% {
  comp_res <- readRDS(here::here(paste0("data/compare_sim_res/",file_list[i])))
  
  ## Obtain information from filename
  file_str <- file_list[i]
  file_str_split <- strsplit(file_str, split = "_")
  # for non-narrow condition
  if(length(file_str_split[[1]]) == 5){
  dgp_it <- file_str_split[[1]][2]
  change_it <- file_str_split[[1]][3]
  tp_it <- file_str_split[[1]][4]
  comp_it <- file_str_split[[1]][5]
  # delete file ending 
  comp_it <- gsub("\\..*", "", comp_it)
  }
  # for narrow condition
  if(length(file_str_split[[1]]) == 6){
  dgp_it <- paste(file_str_split[[1]][2], file_str_split[[1]][3], sep = "_")
  change_it <- file_str_split[[1]][4]
  tp_it <- file_str_split[[1]][5]
  comp_it <- file_str_split[[1]][6]
  # delete file ending 
  comp_it <- gsub("\\..*", "", comp_it)
  }


  
  
  ## Evaluation
  # Loop over all comparisons
  eval_res <- list()
  eval_res <- lapply(comp_res, function(x){
    
    res <- tryCatch({within_compare_eval(x, kappa = FALSE)}, error = function(e) NA)
    res$dgp <- dgp_it
    res$change <- change_it
    res$tp <- tp_it
    res$comp <- comp_it
    if(is.list(x)){
      res$emp <-  x$emp[1]
    } else{
      res$emp <- NA
    }
    return(res)
  })
  
  
  
  ## Output
  # Combine all results into dataframe
  df_eval_res <- do.call(rbind.data.frame, eval_res)
  print(paste0("File ", i, " done!"))
  
  # Save output
  saveRDS(df_eval_res, file = here::here(paste0("data/compare_sim_eval/eval_res_",dgp_it, "_",change_it,"_", tp_it, "_",comp_it, ".RDS")))
  
}
stopCluster(cl)

time_after_within_eval <- Sys.time() - time_before_within_eval  # ~12 mins

# df_comp_res <- do.call(rbind, l_comp_res)
# write_rds(df_comp_res, "df_comp_res.RDS")


# Check which files are missing
exist_files_res <- list.files(path = here::here("data/compare_sim_res"))
exist_files_eval <- list.files(path = here::here("data/compare_sim_eval"))
desired_files <- gsub("comp", "eval_res",exist_files_res)

desired_files <- setdiff(desired_files, exist_files_eval)
file_list <- gsub("eval_res", "comp",desired_files)

# This then has to be passed back to the loop above
to_del <- list.files(path = here::here("data/compare_sim_eval/"), pattern = "narrow")
file.remove(from = paste0(here::here("data/compare_sim_eval/"), to_del))



```


Read in results again, they were saved as individual files. 
```{r}
file_list <- list.files(path = "data/compare_sim_eval", full.names = TRUE)
l_comp_res <- lapply(file_list, readRDS)
df_comp_res <- do.call(rbind, l_comp_res)

# write_rds(df_comp_res, here::here("data/df_comp_res_3103.RDS"))
df_comp_res <- readRDS(here::here("data/df_comp_res_3103.RDS"))
```


Investigate nonconvergence:
```{r}
df_comp_res %>% 
  filter(is.na(emp)) %>% 
  count()    # 103800 did not converge
# everything in the change1.6 condition, probably happens because raw coefficients are too large

df_comp_res %>% 
  filter(is.na(emp)) %>% 
  group_by(comp, dgp, change, tp) %>% 
  count() %>% 
  View()

```



### Plotting Posterior Bootstrap approach
General plotting preparation
TODO: account for narrow priors!
```{r}
change_names <- c("change1.2" = paste("Largest", "\u00D7", "1.2"),
                  "change1.4" = paste("Largest", "\u00D7", "1.4"),
                  "change1.6" = paste("Largest", "\u00D7", "1.6"),
                  "noise0.1" = "",
                  "noise0.2" = "",
                  "noise0.3" = "",
                  "permute" = ""
)

graph_names <- c("graph3" = "Empirical\nSparse",
                 "graph4" = "Simulated\nChain",
                 "graph5" = "Simulated\nNonsparse")

norm_names <- c("frob" = "Frobenius",
                "l1" = "\u2113[1]",
                "maxdiff" = "Maxdiff")

tp_levels <- c("50" = "1", "100" = "2", "200" = "3", "400" = "4", "1000" = "5")

# Restructure results for proper plotting
df_comp_res <- df_comp_res %>% 
  mutate(comp = as.factor(comp)) %>% 
  mutate(comp = forcats::fct_relevel(comp, "l1")) %>% 
  mutate(change = gsub("permute134256", "permute", change))




```





#### Power
n  = 2450. Combinatorics for 50 elements gives 1225, but we have two graphs two draw from, so 2450.

```{r}
v_graphs <- c("graph1", "graph2", "graph3", "graph4", "graph5")

for(g in v_graphs){
  
  p <- df_comp_res %>%
          pivot_longer(cols = c("beta_a", "beta_b", "pcor_a", "pcor_b"), names_to = "res") %>%
          filter(dgp == g) %>%
          mutate(sig05 = ifelse(value < 50, 1, 0),
                 sig01 = ifelse(value < 10, 1, 0)) %>%
          group_by(comp, tp, change, res) %>%
          mutate(n_comp = n()) %>%
          # need the max here so that it reduces to one row
          # n_comp is the same for every row anyway
          summarize(power05 = sum(sig05)/max(n_comp)) %>%
          ungroup() %>%
          mutate(res = case_match(res,
                                  "beta_a" ~ "Temporal A",
                                  "beta_b" ~ "Temporal B",
                                  "pcor_a" ~ "Contemp. A",
                                  "pcor_b" ~ "Contemp. B")) %>% 
          ggplot(aes(x = as.numeric(tp), y = power05, col = comp)) +
          geom_line()+
          facet_grid(change ~ res)+
          theme_minimal()+
          ggokabeito::scale_color_okabe_ito()+
          labs(caption = g,
               x = "Timepeoints",
               y = "Power")
  
  ggsave(filename = paste0("plot_power05_abseparate_", g, ".svg"),p, device = "svg",
         path = here("figures/"), height = 10, width = 7)
  print(p)
}
```








#### Posterior Diff > Empirical
Instead of power, we can plot the median number of bootstrapped differences larger than empirical.

```{r}
v_graphs <- c("graph1", "graph2", "graph3", "graph4", "graph5")

for(g in v_graphs){
  
  p <- df_comp_res %>% 
          pivot_longer(cols = c("beta_a", "beta_b", "pcor_a", "pcor_b"), names_to = "res") %>% 
          filter(dgp == g) %>% 
          mutate(comp = as.factor(comp),
                 tp = as.numeric(tp),
                 change = as.factor(change),
                 res = as.factor(res)) %>% 
          dplyr::group_by(comp, tp, change, res) %>%
          dplyr::summarize(pct_larger = value/10) %>%
          dplyr::summarize(pct_larger = mean(pct_larger)) %>% 
          ggplot(aes(x = as.numeric(tp), y = pct_larger, col = comp)) + 
          # geom_text(aes(label = round(pct_larger,1)), size = 4)+
          geom_line()+
          facet_grid(change ~ res)+
          theme_minimal()+
          scale_color_okabe_ito()+ 
          labs(caption = g,
               x = "Timepeoints",
               y = "% larger than empirical")
  
  ggsave(filename = paste0("plot_count_difference_", g, ".svg"),p, device = "svg",
         path = here("figures/"), height = 10, width = 7)
  print(p)
}




```




### Decision Rule
What happens to power/false positives if we implement the following decision rule:
If either A or B are "significant", we have evidence for a difference in the networks.

Decision rule figure in loop 
```{r}
v_graphs <- c("graph1", "graph2", "graph3", "graph4", "graph5")

for(g in v_graphs){
  
  p <- df_comp_res %>% 
          filter(dgp == g) %>% 
          # setup decision rule
          mutate(sig_beta05 = ifelse(beta_a < 50 | beta_b < 50, 1, 0),
                 sig_pcor05 = ifelse(pcor_a < 50 | pcor_b < 50, 1, 0)) %>% 
          group_by(dgp, comp, tp, change) %>% 
          mutate(n_comp = n()) %>% 
          summarize(power_beta05 = sum(sig_beta05)/n_comp,
                    power_pcor05 = sum(sig_pcor05)/n_comp) %>% 
          # somehow does not cut everything if I don't do this
          # TODO
          summarize(power_beta05 = mean(power_beta05),
                    power_pcor05 = mean(power_pcor05)) %>% 
          pivot_longer(cols = c("power_beta05", "power_pcor05"), names_to = "res") %>% 
          ggplot(aes(x = as.numeric(tp), y = value, col = comp)) + 
          geom_line()+
          facet_grid(change ~ res)+
          theme_minimal()+
          theme_compare+
          labs(caption = paste0("Power of decision rule \"OR\" for ", g))
  
  ggsave(filename = paste0("plot_dec_rule_", g, ".svg"),p, device = "svg",
         path = here("figures/"))
  print(p)
}


```


Decision Rule into one plot.
```{r}
plot_dec_rule <- df_comp_res %>% 
          dplyr::filter(dgp %in% c("graph3", "graph4", "graph5")) %>% 
          dplyr::filter(change != "change1.2") %>% 
          # mutate tp_ind into factor
          mutate(tp = as.factor(tp)) %>% 
          mutate(tp = forcats::fct_relevel(tp, "50", "100", "200", "400", "1000")) %>% 
          mutate(dgp = case_match(dgp,
                                  "graph3" ~ "Empirical Sparse",
                                  "graph4" ~ "Simulated Chain",
                                  "graph5" ~ "Simulated Nonsparse")) %>% 
          # setup decision rule
          dplyr::mutate(sig_beta05 = ifelse(beta_a < 50 | beta_b < 50, 1, 0),
                 sig_pcor05 = ifelse(pcor_a < 50 | pcor_b < 50, 1, 0)) %>% 
          dplyr::group_by(dgp, comp, tp, change) %>% 
          dplyr::mutate(n_comp = n()) %>% 
          dplyr::summarize(power_beta05 = sum(sig_beta05)/n_comp,
                    power_pcor05 = sum(sig_pcor05)/n_comp) %>% 
          # somehow does not cut everything if I don't do this
          # TODO
          dplyr::summarize(power_beta05 = mean(power_beta05),
                    power_pcor05 = mean(power_pcor05)) %>% 
          tidyr::pivot_longer(cols = c("power_beta05", "power_pcor05"), names_to = "res") %>%
          dplyr::mutate(res = case_match(res,
                                         "power_beta05" ~ "Temporal",
                                         "power_pcor05" ~ "Contemporaneous")) %>% 
          ggplot(aes(x = tp, y = value, col = comp, group = comp)) + 
          geom_line()+
          ggh4x::facet_nested(change ~ dgp + res, scales = "free_y",
                             strip = strip_nested(background_y = list(
                                NULL,
                                NULL,
                                NULL,
                                NULL,
                                NULL,
                                NULL,
                                element_rect(colour = "grey")
                              )))+
          theme_compare()+
          # leave this out and delete scales argument above to switch to old plot
          ggh4x::facetted_pos_scales(y = list(
            scale_y_continuous(breaks = c(0,0.25, 0.5, 0.75, 1)),
            scale_y_continuous(breaks = c(0,0.25, 0.5, 0.75, 1)),
            scale_y_continuous(breaks = c(0,0.25, 0.5, 0.75, 1)),
            scale_y_continuous(breaks = c(0,0.25, 0.5, 0.75, 1)),
            scale_y_continuous(breaks = c(0,0.25, 0.5, 0.75, 1)),
            scale_y_continuous(breaks = c(0,0.25, 0.5, 0.75, 1)),
            scale_y_continuous(limits = c(0,0.1), guide = guide_axis(title = "rescaled"))
          ))+
          ggokabeito::scale_colour_okabe_ito()+
          labs(caption = paste0("Power of decision rule \"OR\" at 5% level"),
               x = "Timepoints",
               y = "Power",
               col = "Norm")

plot_dec_rule
ggsave(filename = paste0("plot_dec_rule_new.svg"),plot_dec_rule, device = "svg",
         path = here::here("figures/"), width = 13, height = 10)

```




#### False Positives
Plot false positives across graphs. 
In loop:
```{r}
v_graphs <- c("graph1", "graph2", "graph3", "graph4", "graph5")

for(g in v_graphs){
  
  p <- df_comp_res %>%
          # dplyr::filter(dgp %in% c("graph3", "graph4", "graph5")) %>%
          filter(dgp == g) %>%
          filter(change == "truegraph") %>%
          # setup decision rule
          mutate(sig_beta05 = ifelse(beta_a < 50 | beta_b < 50, 1, 0),
                 sig_pcor05 = ifelse(pcor_a < 50 | pcor_b < 50, 1, 0)) %>%
          # mutate tp_ind into factor
          mutate(tp = as.factor(tp)) %>%
          mutate(tp = forcats::fct_relevel(tp, "50", "100", "200", "400", "1000")) %>%
          mutate(dgp = case_match(dgp,
                                  "graph3" ~ "Empirical Sparse",
                                  "graph4" ~ "Simulated Chain",
                                  "graph5" ~ "Simulated Nonsparse")) %>%
          group_by(dgp, comp, tp, change) %>%
          mutate(n_comp = n()) %>%
          summarize(fp_beta05 = sum(sig_beta05)/n_comp,
                    fp_pcor05 = sum(sig_pcor05)/n_comp) %>%
          # somehow does not cut everything if I don't do this
          # TODO
          summarize(fp_beta05 = mean(fp_beta05),
                    fp_pcor05 = mean(fp_pcor05)) %>%
          rename("Temporal" = fp_beta05,
                 "Contemporaneous" = fp_pcor05) %>%
          pivot_longer(cols = c("Temporal", "Contemporaneous"), names_to = "res") %>%
          ggplot(aes(x = as.numeric(tp), y = value, col = comp)) +
          geom_line()+
          facet_grid(.~ res)+
          theme_minimal()+
          ylim(0,.1)+
          ggokabeito::scale_color_okabe_ito()+
          labs(caption = paste0("False Positives for ", g),
               x = "Timepoints")
  
  ggsave(filename = paste0("plot_fp05_", g, ".svg"),p, device = "svg",
         path = here("figures/"))
  print(p)
}

```

In one graph:
```{r}
plot_false_positive <- df_comp_res %>%
          dplyr::filter(dgp %in% c("graph3", "graph4", "graph5")) %>%
          filter(change == "truegraph") %>%
          # setup decision rule
          mutate(sig_beta05 = ifelse(beta_a < 50 | beta_b < 50, 1, 0),
                 sig_pcor05 = ifelse(pcor_a < 50 | pcor_b < 50, 1, 0)) %>%
          # mutate tp_ind into factor
          mutate(tp = as.factor(tp)) %>%
          mutate(tp = forcats::fct_relevel(tp, "50", "100", "200", "400", "1000")) %>%
          mutate(dgp = case_match(dgp,
                                  "graph3" ~ "Empirical Sparse",
                                  "graph4" ~ "Simulated Chain",
                                  "graph5" ~ "Simulated Nonsparse")) %>%
          group_by(dgp, comp, tp, change) %>%
          mutate(n_comp = n()) %>%
          summarize(fp_beta05 = sum(sig_beta05)/n_comp,
                    fp_pcor05 = sum(sig_pcor05)/n_comp) %>%
          # somehow does not cut everything if I don't do this
          # TODO
          summarize(fp_beta05 = mean(fp_beta05),
                    fp_pcor05 = mean(fp_pcor05)) %>%
          rename("Temporal" = fp_beta05,
                 "Contemporaneous" = fp_pcor05) %>%
          pivot_longer(cols = c("Temporal", "Contemporaneous"), names_to = "res") %>%
          ggplot(aes(x = tp, y = value, col = comp, group = comp)) +
          geom_line()+
          ggh4x::facet_nested(. ~ dgp + res)+
          theme_minimal()+
          ylim(0,.1)+
          ggokabeito::scale_color_okabe_ito()+
          theme_compare()+
          geom_hline(yintercept = 0.05, col = "#D5D8DC")+ 
          labs(caption = paste0("False Positives at 5% level"),
               x = "Timepoints", 
               col = "Norm",
               y = "Proportion of false positives")

plot_false_positive
ggsave(filename = paste0("plot_false_positive.svg"),plot_false_positive, device = "svg",
         path = here::here("figures/"), width = 12, height = 6)


```


### Prior sensitivity graph
To keep everything clearer visually, we only use one norm (Frobenius) for now. 
```{r}
plot_dec_rule_prior_sens <- df_comp_res %>% 
          dplyr::filter(comp == "frob") %>% 
          dplyr::filter(dgp %in% c("graph3", "graph4", "graph5",
                                   "narrow_graph3", "narrow_graph4", "narrow_graph5")) %>% 
          dplyr::filter(change != "change1.2") %>% 
          mutate(dgp = case_match(dgp,
                                  "graph3" ~ "wide_graph3",
                                  "graph4" ~ "wide_graph4",
                                  "graph5" ~ "wide_graph5",
                                  .default = dgp)) %>% 
          # mutate tp_ind into factor
          mutate(tp = as.factor(tp)) %>% 
          mutate(tp = forcats::fct_relevel(tp, "50", "100", "200", "400", "1000")) %>% 
          # separate graph and prior
          tidyr::separate_wider_delim(cols = dgp, delim = "_", names = c("prior", "dgp")) %>% 
          mutate(dgp = case_match(dgp,
                                  "graph3" ~ "Empirical Sparse",
                                  "graph4" ~ "Simulated Chain",
                                  "graph5" ~ "Simulated Nonsparse")) %>% 
          # setup decision rule
          dplyr::mutate(sig_beta05 = ifelse(beta_a < 50 | beta_b < 50, 1, 0),
                 sig_pcor05 = ifelse(pcor_a < 50 | pcor_b < 50, 1, 0)) %>% 
          dplyr::group_by(dgp, comp, tp, change, prior) %>% 
          dplyr::mutate(n_comp = n()) %>% 
          dplyr::summarize(power_beta05 = sum(sig_beta05)/n_comp,
                    power_pcor05 = sum(sig_pcor05)/n_comp) %>% 
          # somehow does not cut everything if I don't do this
          # TODO
          dplyr::summarize(power_beta05 = mean(power_beta05),
                    power_pcor05 = mean(power_pcor05)) %>% 
          tidyr::pivot_longer(cols = c("power_beta05", "power_pcor05"), names_to = "res") %>%
          dplyr::mutate(res = case_match(res,
                                         "power_beta05" ~ "Temporal",
                                         "power_pcor05" ~ "Contemporaneous")) %>% 
          ggplot(aes(x = tp, y = value, col = prior, group = prior)) + 
          geom_line()+
          ggh4x::facet_nested(change ~ dgp + res)+
          ggokabeito::scale_colour_okabe_ito()+
          theme_compare()+
          labs(caption = paste0("Power of decision rule \"OR\" at 5% level"),
               x = "Timepoints",
               y = "Power",
               col = "Prior")


plot_dec_rule_prior_sens
ggsave(filename ="plot_dec_rule_prior_sens.svg",plot_dec_rule_prior_sens, device = "svg",
         path = here::here("figures/"), width = 13, height = 10)
```








### Norms across conditions
How large are the norms across the simulation conditions?
```{r}
v_graphs <- c("graph1", "graph2", "graph3", "graph4", "graph5", "graph6")

for(g in v_graphs){
  
  p <- df_comp_res %>% 
        filter(dgp == g) %>% 
        mutate(comp = as.factor(comp),
               tp = as.numeric(tp),
               change = as.factor(change),
               emp  = as.numeric(emp)) %>% 
        group_by(comp, dgp, change, tp) %>% 
        summarize(mean_emp = mean(emp),
                  sd_emp = sd(emp)) %>%
        ggplot(aes(x = as.numeric(tp), y = mean_emp, col = comp))+
        geom_line()+
        geom_ribbon(aes(ymin = mean_emp - sd_emp, ymax = mean_emp + sd_emp, fill = comp), 
                    alpha = 0.4, colour = NA)+
        ggh4x::facet_grid2(change ~ comp, scales = "free", independent = "y")+
        theme_minimal()+
        scale_color_okabe_ito()+
        scale_fill_okabe_ito()+
        labs(caption = g,
             x = "Timepoints",
             y = "Mean Distance")

  
  ggsave(filename = paste0("plot_emp_norms_", g, ".svg"),p, device = "svg",
         path = here("figures/"))
  print(p)
}
```






