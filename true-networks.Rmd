---
title: "true-networks"
author: "Bj√∂rn Siepe"
date: "`r Sys.Date()"
output: html_document
---

```{r setup}
library(dplyr)
library(lme4)
library(ggplot2)
library(dplyr)
library(tidyr)
library(qgraph)
library(tidyselect)
library(mlVAR)
library(viridis)
library(summarytools)
library(lm.beta)
library(RColorBrewer)
library(Matrix)
library(matrixcalc)
library(here)

here::i_am("var-compare.Rproj")
seed = 2022
set.seed(seed)
```


# Own simulated graph (graph1)
This is no longer used as the values were unrealistically high.
Still keep this here for transparency.
```{r}
# Ground truth model is still generated with graphicalVAR 
set.seed(2022)    
og_graph <- randomGVARmodel(Nvar = 6, probKappaEdge = 0.5, probBetaEdge = 0.3)
beta <- as.matrix(read.table(header = FALSE, colClasses = "numeric", text = "
 0.2266407 0.0000000  0.0000000 -0.2668593  0.0000000 0.0000000
-0.7380388 0.2266407  0.0000000  0.0000000 -0.9288327 0.0000000
 0.0000000 0.0000000  0.2266407  0.9571318  0.2409225 0.5543485
 0.0000000 0.0000000  0.0000000  0.2266407 -0.7438448 0.0000000
 0.5214148 0.0000000  0.0000000  0.0000000  0.2266407 0.0000000
 0.0000000 0.0000000 -0.8903007  0.0000000  0.0000000 0.2266407"))
kappa <- as.matrix(read.table(header = FALSE, colClasses = "numeric", text = "
 1.0000000  0.0000000  0.0000000 0.0000000  0.4018933 0.3717013
 0.0000000  1.0000000  0.2266407 0.5527593 -0.2654634 0.2593779
 0.0000000  0.2266407  1.0000000 0.0000000 -0.3318945 0.3175423
 0.0000000  0.5527593  0.0000000 1.0000000  0.0000000 0.0000000
 0.4018933 -0.2654634 -0.3318945 0.0000000  1.0000000 0.0000000
 0.3717013  0.2593779  0.3175423 0.0000000  0.0000000 1.0000000"))

# compute partial correlations from kappa
pcc <- -cov2cor(kappa)
graph <- list()
graph$beta <- beta
graph$kappa <- kappa
graph$PCC <- pcc
diag(graph$PCC) <- rep(0,6)
dimnames(graph$beta) <- NULL
dimnames(graph$kappa) <- NULL

graph2 <- graph
graph2$beta <- graph2$beta + runif(36, -0.05, 0.05)
graph2$kappa <- graph2$kappa + runif(36, -0.05, 0.05)
diag(graph2$kappa) <- c(1,1,1,1,1,1)
graph2$kappa <- Matrix::forceSymmetric(graph2$kappa)
l_graph <- list(graph = graph,
                graph2 = graph2)

write_rds(graph, here("data/graph.RDS"))

```



# Non-sparse graph (graph2)
No longer used, same reasons for including as above.
```{r}
# Obtain random GVARmodel
full_graph <- randomGVARmodel(6, probKappaEdge = .3, probBetaEdge = .3)

# Generate data 
full_graph_dat <- graphicalVARsim(5000, beta = full_graph$beta, kappa = full_graph$kappa, mean = 0)
full_graph_dat <- as.data.frame(full_graph_dat)

# Reestimate a graph on this data set
full_graph_est_bggm <- BGGM::var_estimate(as.data.frame(full_graph_dat),
                                     beta_sd = 1,
                                     rho_sd = .3)

# Obtain kappa_mu
full_graph_est_bggm$fit$kappa <- array(apply(full_graph_est_bggm$fit$Sigma, 3, solve),
                                       dim = dim(full_graph_est_bggm$fit$Sigma))

# Calculate mean of kappa
full_graph_est_bggm$kappa_mu <- apply(full_graph_est_bggm$fit$kappa, c(1,2), mean)

# This gives us shitty kappas. Instead, fit unregularized graphicalVAR to obtain estimates
# This actually gives us very similar kappas!
full_graph_est <- graphicalVAR(full_graph_dat, lambda_beta = 0, lambda_kappa = 0)

# What happens in regularization?
full_graph_est_reg <- graphicalVAR(full_graph_dat)

# Compare to bggm
full_graph_est$kappa
full_graph_est_bggm$kappa_mu


-cov2cor(full_graph$kappa)
full_graph$PCC

write_rds(full_graph_est_bggm, "full_graph.RDS")

```


# Fried 2020
Here, I use code by Mansueto et al. (2022) to obtain the mlVAR network and extract coefficients to simulate from. 
It's based on https://osf.io/7fpw5, data can be obtained from https://osf.io/5a2ub.
```{r preparation}
set.seed(2022)
load(here::here("data/clean_network.RData"))
Data5b <- Data2

# Alpha to detrend:
alpha <- 0.05

# Variables to investigate:
vars <- c("Q1","Q2","Q3","Q4","Q5","Q6","Q7","Q8","Q9","Q10","Q11","Q12","Q13","Q14","Q15","Q16","Q17","Q18")

# Labels:
varLabs <- c("Relax","Irritable","Worry","Nervous","Future","Anhedonia",
             "Tired","Hungry","Alone","Angry","Social_offline","Social_online","Music",
             "Procrastinate","Outdoors","C19_occupied","C19_worry","Home")


names(Data5b)[names(Data5b) %in% vars] <- varLabs

# Remove items:
Data5b <- Data5b %>% 
  dplyr::select(!c(Hungry,Angry,Music,Procrastinate))
varLabs <- varLabs[!varLabs %in% c("Hungry","Angry","Music","Procrastinate")]

# Data frame with empty values for fitted effects (all):
fitted_all <- expand.grid(
  beep = seq(min(Data5b$beep),max(Data5b$beep)),
  day = seq(min(Data5b$day),max(Data5b$day))
)

# Data frame with empty values for day trends:
fitted_day <- data.frame(
  day = seq(min(Data5b$day),max(Data5b$day))
)

# Data frame with empty values for beeps:
fitted_beep <- data.frame(
  beep = seq(min(Data5b$beep),max(Data5b$beep))
)

# Data frame to store p-values:
p_values <- data.frame(
  var = c("day", "beep")
)

# Also empty data frame list for test statistics:
testStatistics <- list()
coefficients <- list()
stdcoefficients <- list()

# Make the beep variable factor in dataset:
Data5b$beepFactor <- factor(Data5b$beep, levels = 0:3, labels = c("09:00 - 12:00","12:00 - 15:00","15:00 - 18:00","18:00 - 21:00"))
fitted_all$beepFactor <- factor(fitted_all$beep, levels = 0:3, labels = c("09:00 - 12:00","12:00 - 15:00","15:00 - 18:00","18:00 - 21:00"))
fitted_beep$beepFactor <- factor(fitted_beep$beep, levels = 0:3, labels = c("09:00 - 12:00","12:00 - 15:00","15:00 - 18:00","18:00 - 21:00"))

# Make day variable for dates:
Data5b$date <- as.Date("2020-03-15") + Data5b$day
fitted_all$date <- as.Date("2020-03-15") + fitted_all$day
fitted_day$date <- as.Date("2020-03-15") + fitted_day$day

# Add the midpoints as time variable:
Data5b$midTime <- as.character(factor(Data5b$beep, levels = 0:3, labels = c("10:30","13:30","16:30","19:30")))
Data5b$midTime <- as.POSIXct(paste(Data5b$date,Data5b$midTime), format = "%Y-%m-%d %H:%M", tz = "Europe/Amsterdam")

fitted_all$midTime <- as.character(factor(fitted_all$beep, levels = 0:3, labels = c("10:30","13:30","16:30","19:30")))
fitted_all$midTime <- as.POSIXct(paste(fitted_all$date,fitted_all$midTime), format = "%Y-%m-%d %H:%M", tz = "Europe/Amsterdam")

# Data frame to store detrended data:
data_detrended <- Data5b

# Fix curves:
for (v in seq_along(varLabs)){
  formula <- as.formula(paste0(varLabs[v], " ~ 1 + day + factor(beep)")) #why 1? With or without 1 results seem to be the same
  lmRes <- lm(formula, data = Data5b)
  
  # Fixed effects:
  fixed <- coef(lmRes)
  
  # make zero if not significant at alpha:
  p_values[[varLabs[v]]] <- anova(lmRes)[["Pr(>F)"]][1:2]
  if (p_values[[varLabs[v]]][1] > alpha){
    fixed[2] <- 0
  }
  if (p_values[[varLabs[v]]][2] > alpha){
    fixed[3:5] <- 0
  }
  
  # Add to DFs:
  fitted_all[,varLabs[v]] <- fixed[1] + fixed[2] * fitted_all[["day"]]  +  fixed[3] * (fitted_all[["beep"]] == 1)  + 
  fixed[4] * (fitted_all[["beep"]] == 2) + fixed[5] *  (fitted_all[["beep"]] == 3)
  
  fitted_day[,varLabs[v]] <- fixed[1] + fixed[2] * fitted_day[["day"]]
  
  fitted_beep[,varLabs[v]] <- fixed[1] + fixed[2] * median(fitted_day[["day"]]) +  fixed[3] * (fitted_beep[["beep"]] == 1)  + 
    fixed[4] * (fitted_beep[["beep"]] == 2) + fixed[5] *  (fitted_beep[["beep"]] == 3)
  
  # Detrend data:
  data_detrended[,varLabs[v]] <- Data5b[,varLabs[v]] - (fixed[1] + fixed[2] * Data5b[["day"]]  +  fixed[3] * (Data5b[["beep"]] == 1)  + 
    fixed[4] * (Data5b[["beep"]] == 2) + fixed[5] *  (Data5b[["beep"]] == 3))
  
  # Test statistic dataframe:
  ids <- rownames(anova(lmRes))
  testStatistics[[v]] <- cbind(data.frame(var = varLabs[v], effect = ids), anova(lmRes))
  
  coefficients[[v]] <- data.frame(
    var = varLabs[v],
    type = names(coef(lmRes)),
    coef = coef(lmRes),
    std = coef(lm.beta(lmRes))
  )
}

```



I get the following warnings: 
"Warnung: Some beeps are recorded more than once! Results are likely unreliable.
Check the beep warning:
```{r}
data_detrended %>% 
  group_by(id, day, beep) %>% 
  count() %>% 
  filter(n>1) %>% 
  View()


# Seemingly, these are all NA beeps
data_detrended %>% 
  filter(id == 40) %>% 
  View()

```

Warnung: 4 subjects detected with < 20 measurements. This is not recommended, as within-person centering with too few observations per subject will lead to biased estimates (most notably: negative self-loops). Estimating temporal and between-subjects effects"

I did not change code to accomodate that to keep everything close to the original.


Fit the model:
```{r}
data_detrended$Anxiety <- rowMeans(dplyr::select(data_detrended, Irritable, Worry, Nervous, Relax), na.rm = FALSE)
data_detrended$Depression <- rowMeans(dplyr::select(data_detrended, Anhedonia, Future, Tired), na.rm = FALSE)

varLabs3 <- c("Anxiety", "Depression", "Alone","Social_offline","Social_online",
             "Outdoors","C19_occupied","C19_worry","Home")

# Run mlVAR (correlated):
res3 <- mlVAR(data_detrended,
              vars=varLabs3,
              idvar="id",
              dayvar="day",
              beepvar="beep",
              lags = 1,
              temporal = "correlated",
              contemporaneous = "correlated",
              nCores = 13)

# # # delete irrelevant data storage
# # res3 <- res3[res3!="data"]
# saveRDS(res3, here("data/network_correlated_Fried2020_9n_final.RData"))
# # load model
# res3<-readRDS(here("data/network_correlated_Fried2020_9n_final.RData"))

# Names for the Plot :
 names <- c("Anxiety", "Depression", "Alone", 
            "Social Offline", "Social Online", "Outdoors",
            "C19 Occupied", "C19 Worry", "Home") 

# Get the contemporaneous and temporal networks:
cont6 <- getNet(res3, "contemporaneous", layout = "spring", nonsig = "hide", rule = "and")
#bet6 <- getNet(res3, "between", nonsig = "hide", rule = "and")
temp6 <- getNet(res3, "temporal", nonsig = "hide")

```


Get relevant statistics:
```{r extract-coefs}
# beta 
beta_dataset2_9n <- res3$results$Beta$mean[,,1] * t(temp6 != 0)

# partial correlations
omega_dataset2_9n <- res3$results$Theta$pcor$mean * (cont6 != 0)

# precision matrix
theta_dataset2_9n <- res3$results$Theta$prec$mean * (cont6 != 0 | diag(ncol(cont6)) == 1)

# Compute PDC as well
PDC6 <- graphicalVAR:::computePDC(beta = beta_dataset2_9n, kappa = theta_dataset2_9n)

# save them all in one list
graph_fried <- list()
graph_fried[["beta"]] <- beta_dataset2_9n
graph_fried[["pcor"]] <- omega_dataset2_9n
graph_fried[["kappa"]] <- theta_dataset2_9n 
graph_fried[["pdc"]] <- PDC6

# write_rds(graph_fried, here("data/graph_fried.Rds"))
```


# Chain Graph Hoekstra et al. 2022 (Graph 4)
This uses the PDC and PCC of Hoekstra et al. (2022) and pretends as if they were beta/kappa matrices.
```{r}
hoekstra_synth <- list()
hoekstra_synth$beta <- as.matrix(read.table(header = FALSE, colClasses = "numeric", text = "
0.29 0.32 0 0 0 0 0 0
0 0.13 -0.36 0 0 0 0 0
0 0 0.37 -0.47 0 0 0 0
0 0 0 0.32 0.27 0 0 0
0 0 0 0 0.44 -0.24 0 0
0 0 0 0 0 0.44 -0.33 0
0 0 0 0 0 0 0.50 0.24
0.34 0 0 0 0 0 0 0.42"))

hoekstra_synth$kappa <- as.matrix(read.table(header = FALSE, colClasses = "numeric", text = "
0 -0.27 0 0 0 0 0 -0.29
-0.27 0 0.49 0 0 0 0 0
0 0.49 0 0.22 0 0 0 0
0 0 0.22 0 -0.36 0 0 0
0 0 0 -0.36 0 0.52 0 0
0 0 0 0 0.52 0 0.29 0
0 0 0 0 0 0.29 0 -0.30
-0.29 0 0 0 0 0 -0.30 0"))

diag(hoekstra_synth$kappa) <- rep(1, nrow(hoekstra_synth$kappa))

# Cut to 6 nodes
# Reconnect last nodes again
hoekstra_synth_6node <- list()
hoekstra_synth_6node$beta <- hoekstra_synth$beta[c(1:6), c(1:6)]
hoekstra_synth_6node$beta[1,6] <- 0.34

hoekstra_synth_6node$kappa <- hoekstra_synth$kappa[c(1:6), c(1:6)]
hoekstra_synth_6node$kappa[1,6] <- -0.29
hoekstra_synth_6node$kappa[6,1] <- -0.29

saveRDS(hoekstra_synth, "data/hoekstra_synth_9node.RDS")
saveRDS(hoekstra_synth_6node, "data/hoekstra_synth_6node.RDS")

```


# Nonsparse Graph 2 (Graph 5)
Previous nonsparse graph had betas that were too high. 
We use graph on Fried data and add noise everywhere. 
```{r}
graph_fried <- readRDS(here::here("data/graph_fried.Rds"))
graph5 <- list()
graph5$beta <- graph_fried$beta[1:6,1:6]
graph5$kappa <- graph_fried$kappa[1:6,1:6]

# Find maximum and minimum values, which serve as boundaries for noise
max_beta <- max(graph5$beta)
min_beta <- min(graph5$beta[graph5$beta!=0])

# obtain non-diagonal values
kappa_nondiag <- graph5$kappa[upper.tri(graph5$kappa)]
max_kappa <- max(kappa_nondiag)
min_kappa <- min(kappa_nondiag[kappa_nondiag !=0])

## Add noise
# only to zero elements of existing matrix
graph5$beta[graph5$beta == 0] <- runif(sum(graph5$beta == 0), 
                                       min = min_beta, max = max_beta)
graph5$beta

# for kappa
graph5$kappa[graph5$kappa == 0] <- runif(sum(graph5$kappa == 0), 
                                       min = min_kappa, max = max_kappa)

graph5$kappa <- as.matrix(Matrix::forceSymmetric(graph5$kappa))
matrixcalc::is.positive.semi.definite(graph5$kappa)
graph5$pcor <- -1*stats::cov2cor(graph5$kappa)
diag(graph5$pcor) <- rep(0, 6)
# Has to be made symmetric again, small rounding errors after 7 digits
graph5$pcor <- as.matrix(Matrix::forceSymmetric(graph5$pcor))

saveRDS(graph5, here::here("data/graph5.RDS"))


```


# Summary of data-generating processes

```{r}
sum(graph_fried$beta[1:6, 1:6] != 0)
sum(graph_fried$pcor[1:6, 1:6] != 0)

```



# Plot data-generating processes

Graph Fried/Sparse Empirical:
```{r}
graph_fried <- readRDS(here("data/graph_fried.Rds"))
graph_fried$beta <- graph_fried$beta[1:6, 1:6]
graph_fried$pcor <- graph_fried$pcor[1:6, 1:6]

graph_fried<- lapply(graph_fried, function(x){
  dimnames(x) <- NULL
  return(x)
})
svg(here::here("figures/dgp_fried.svg"), width = 14)
par(mfrow = c(1,2))
qgraph(graph_fried$beta, layout = "circle", theme = "colorblind", 
       edge.labels = TRUE, edge.label.cex = 1.25)
qgraph(graph_fried$pcor, layout = "circle", theme = "colorblind", 
       edge.labels = TRUE, edge.label.cex = 1.25)
dev.off()

# Find median absolute non-zero effect
mean(abs(graph_fried$beta[graph_fried$beta !=0]))
mean(abs(graph_fried$pcor[graph_fried$pcor !=0]))

```


Chain Graph:
Six Nodes:
```{r}
hoekstra_synth_6node<- readRDS("data/hoekstra_synth_6node.RDS")
hoekstra_synth_6node$pcor <- -stats::cov2cor(hoekstra_synth_6node$kappa)


hoekstra_synth_6node<- lapply(hoekstra_synth_6node, function(x){
  dimnames(x) <- NULL
  return(x)
})

diag(hoekstra_synth_6node$pcor) <- rep(0, 6)

svg(here::here("figures/dgp_chain6node.svg"), width = 14)
par(mfrow = c(1,2))
qgraph(hoekstra_synth_6node$beta, layout = "circle", theme = "colorblind", 
       edge.labels = TRUE, edge.label.cex = 1.25)
qgraph(hoekstra_synth_6node$pcor, layout = "circle", theme = "colorblind", 
       edge.labels = TRUE, edge.label.cex = 1.25)
dev.off()

hoekstra_synth_6node$beta

mean(abs(hoekstra_synth_6node$beta[hoekstra_synth_6node$beta !=0]))
mean(abs(hoekstra_synth_6node$pcor[hoekstra_synth_6node$pcor !=0]))

```


Nine Nodes:
(accidentally called 9node, but it is actually 8node)
```{r}
hoekstra_synth<- readRDS("data/hoekstra_synth_9node.RDS")
hoekstra_synth$pcor <- -stats::cov2cor(hoekstra_synth$kappa)

hoekstra_synth <- lapply(hoekstra_synth, function(x){
  dimnames(x) <- NULL
  return(x)
})
diag(hoekstra_synth$pcor) <- rep(0, 8)

svg(here::here("figures/dgp_chain9node.svg"), width = 14)
par(mfrow = c(1,2))
qgraph(hoekstra_synth$beta, layout = "circle", theme = "colorblind", 
       edge.labels = TRUE, edge.label.cex = 1.25)
qgraph(hoekstra_synth$pcor, layout = "circle", theme = "colorblind", 
       edge.labels = TRUE, edge.label.cex = 1.25)
dev.off()
mean(abs(hoekstra_synth$beta[hoekstra_synth$beta !=0]))
mean(abs(hoekstra_synth$pcor[hoekstra_synth$pcor !=0]))


```


Non-Sparse Graph:
```{r}
non_sparse <- readRDS(here::here("data/graph5.RDS"))
non_sparse <- lapply(non_sparse, function(x){
  dimnames(x) <- NULL
  return(x)
})

svg(here::here("figures/dgp_fried_nonsparse.svg"), width = 14)
par(mfrow = c(1,2))
qgraph(non_sparse$beta, layout = "circle", theme = "colorblind", 
       edge.labels = TRUE, edge.label.cex = 1.25)
qgraph(non_sparse$pcor, layout = "circle", theme = "colorblind", 
       edge.labels = TRUE, edge.label.cex = 1.25)
dev.off()

mean(abs(non_sparse$beta[non_sparse$beta !=0]))
mean(abs(non_sparse$pcor[non_sparse$pcor !=0]))

```









