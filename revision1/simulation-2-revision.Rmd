---
title: "var-resample"
author: "Björn Siepe"
date: "`r Sys.Date()"
output: html_document
---
This document contains code to reproduce simulation study 2. 

# Background
```{r preparations, include = FALSE}
library(tidyverse)
library(graphicalVAR)
library(doParallel)
library(doRNG)         
library(mgm)
library(mlVAR)
library(BGGM)
library(reshape2)      
library(mvtnorm)       
library(stats)     
library(here)
source(here("aux_funs.R"))
library(ggokabeito)
library(Matrix)
library(rrapply)       
library(ggh4x)
library(gt)
library(gtExtras)
here::i_am("var-compare.Rproj")


seed = 2022
set.seed(seed)
```


Intermediate simulation results cannot be loaded here, as the file size is too large.
Feel free to reach out to me to find a way to share the files. 

## Simulation Conditions
```{r}
# Simulation conditions
n_ind <- 100 # number of individuals(so models to create) 
n_tp <- c(50,100,200,400, 1000) # number of timepoints
n_postds <- 120 # number of posterior datasets
seed <- 2022
dgp_names <- c("graph1", "graph2", "graph3", "graph4", "graph5")
```


## Change Graphs
Now we can change all graphs according to the simulation conditions.
```{r change-graphs}
l_graphs <- readRDS("data/l_graphs.RDS")
l_graphs <- l_graphs[-6]   # 9 node graph not used here

# Apply change function to every graph
l_changed_graphs <- lapply(l_graphs,
                           function(x) {change_graphs(
                                            truegraph = x,
                                            changemax = c(1.4, 1.6),
                                            noise = c(0.1,0.2,0.3),
                                            const = c(0.05, 0.1, 0.15),
                                            permute_active = FALSE,
                                            seed = seed)})


# write_rds(l_changed_graphs, "data/l_changed_graphs_0305.RDS")
l_changed_graphs <- readRDS("data/l_changed_graphs_0305.RDS")

```

Get change matrices for supplement
```{r}
l_diff_mat <- list()

# loop over dgps 
for(i in 1:5){
  l_diff_mat[[i]] <- list()
  # loop over noise structures
  ct <- 0
  for(ch in 7:9){
    ct <- ct+1
    l_diff_mat[[i]][[ct]] <- list()
    l_diff_mat[[i]][[ct]]$beta <- round(l_changed_graphs[[i]][[ch]]$beta-l_changed_graphs[[i]]$truegraph$beta,3)
    l_diff_mat[[i]][[ct]]$pcor <- round((-1*stats::cov2cor(l_changed_graphs[[i]][[ch]]$kappa))-(-1*stats::cov2cor(l_changed_graphs[[i]]$truegraph$kappa)),3)
  }
    
  
}

# function from https://www.r-bloggers.com/2020/08/matrix-to-latex/
array_to_latex <- function(arr){
rows <- apply(arr, MARGIN=1, paste, collapse = " & ")
matrix_string <- paste(rows, collapse = " \\\\ ")
return(paste("\\begin{bsmallmatrix}", matrix_string, "\\end{bsmallmatrix}"))
}

# For beta, identical across dgps
array_to_latex(l_diff_mat[[5]][[1]]$beta)
array_to_latex(l_diff_mat[[5]][[2]]$beta)
array_to_latex(l_diff_mat[[5]][[3]]$beta)

lapply(l_diff_mat, function(x){
  lapply(x, function(y) mean(abs(y$beta)))
})


lapply(l_diff_mat, function(x){
  lapply(x, function(y) mean(abs(y$pcor[y$pcor != 0])))
})

# For kappa, slightly different
array_to_latex(l_diff_mat[[3]][[1]]$pcor)
array_to_latex(l_diff_mat[[3]][[2]]$pcor)
array_to_latex(l_diff_mat[[5]][[3]]$pcor)

```



## Simulate Raw Data
Then, generate raw data from data-generating processes. We create more posterior datasets than we fit in the end, but that is irrelevant for simulations (was just built-in for safety).

```{r generate-rawdata-parallel}
# Changed: instead of n_ind, we create n_postds datasets 
# because some models don't converge
before_simraw <- Sys.time()
ncores = 40
cl = makeCluster(ncores)
registerDoParallel(cl)
l_raw_new <- list()

for(dgp in dgp_names){
  l_raw_new[[dgp]] <- list()
  for(t in seq_along(n_tp)){
      l_raw_new[[dgp]][[t]] <- lapply(l_changed_graphs[[dgp]],
                                        function(x) sim_raw_parallel(dgp = x, 
                                                                     n = n_postds, 
                                                                     tp = n_tp[t], 
                                                                     seed = seed, 
                                                                     means = 0, 
                                                                     standardize = TRUE))
    
  }
}

stopCluster(cl)

after_simraw <- Sys.time()-before_simraw  # less than 4 minutes

# write_rds(l_raw, "data/l_raw_new_1703.RDS")
l_raw <- readRDS(here::here("data/l_raw_new_1703.RDS"))

for(dgp in dgp_names){
  for(t in seq_along(n_tp)){
    l_raw[[dgp]][[t]]$noise0.2 <- l_raw_new[[dgp]][[t]]$noise0.2
    l_raw[[dgp]][[t]]$const0.05 <- l_raw_new[[dgp]][[t]]$const0.05
    l_raw[[dgp]][[t]]$const0.1 <- l_raw_new[[dgp]][[t]]$const0.1
    l_raw[[dgp]][[t]]$const0.15 <- l_raw_new[[dgp]][[t]]$const0.15
  }
}

```


### Raw data permutation
As a new change condition, just change variable indexes in the data before fitting. 
```{r}
for(dgp in dgp_names){
  for(t in seq_along(n_tp)){
    l_raw[[dgp]][[t]]$permute <- lapply(l_raw[[dgp]][[t]]$truegraph,
                                  function(x) {
                                    x$data <- x$data[,c(1,3,4,2,5,6)]
                                    x$args$dgp <- "permute134256" 
                                    x
                                  })
    
  }
}
```


# Bayesian approach
Fit a VAR model to each raw dataset. 
```{r}
# model parameters
rho_sd <- 0.5      # Prior for partial correlations
beta_sd <- 1       # Prior for regression matrix
seed <- 2022       # seed
n_iter <- 50000    # number of iterations


# Prior switch
prior_wide <- FALSE
ifelse(prior_wide, 
       {
         rho_sd <- 0.5
         beta_sd <- 1
       },
       {
         rho_sd <- 0.25
         beta_sd <- 0.2
       })



before_fitraw <- Sys.time()
ncores = 50
cl = makeCluster(ncores)
registerDoParallel(cl)
clusterExport(cl, c("fit_var_parallel_merged", "summarize_post"))

# Only compute for specific modification 
l_raw <- lapply(l_raw, function(x) lapply(x, function(y) list(
                                                              const0.05 = y$const0.05,
                                                              const0.1 = y$const0.1,
                                                              const0.15 = y$const0.15,
                                                              noise0.2 = y$noise0.2
                                                              )))

# dgp_names <- c("graph1", "graph2", "graph3", "graph4", "graph5")
dgp_names <- c("graph3", "graph4", "graph5")
for(dgp in dgp_names){
  for(t in seq_along(n_tp)){
    
    # output label based on prior
    dgp_string <- ifelse(prior_wide, dgp, paste0("narrow_",dgp))
    
    lapply(l_raw[[dgp]][[t]], 
           function(x){fit_var_parallel_merged(
                              data = x, 
                              n = n_ind, 
                              nds = n_postds, 
                              rho_prior = rho_sd, 
                              beta_prior = beta_sd, 
                              seed = seed, 
                              iterations = n_iter, 
                              get_kappa = FALSE, 
                              summarize_post = FALSE, 
                              pruneresults = FALSE, 
                              dgp_name = dgp_string, 
                              save_files = TRUE
  )})
  }
}
stopCluster(cl)
after_fitraw <- Sys.time()-before_fitraw


```


Only for the server: move some files to HDD
```{r}
l_copy <- list.files(path = here::here("data/compare_sim_fits"), pattern = "change")
file.copy(from = paste0(here::here("data/compare_sim_fits/"), l_copy),
          to = paste0("/home/bjoern/HDD/var-compare/data/", l_copy))

file.remove(from = paste0(here::here("data/compare_sim_fits/"), l_copy))

```


The other way around:
```{r}
l_copy <- list.files(path = here::here("/home/bjoern/HDD/var-compare/data/"), pattern = "truegraph")
l_copy <- l_copy[!grepl("graph1", l_copy)]
file.copy(from = paste0(here::here("/home/bjoern/HDD/var-compare/data/"), l_copy),
          to = paste0("data/compare_sim_fits/", l_copy))

```


# Posterior Comparison

Compare all models:
```{r}
# Setup list of conditions
# All possible model combinations
comp_combinations <- expand_grid_unique(mod_a = seq(1, n_ind, 1),
                                 mod_b = seq(1, n_ind, 1))
# number of data-generating processes
n_dgp <- 5
# Number of comparison types
n_c_types <- 3

# Number of different graph structures
n_g_types <- 9

# Number of different tp conditions
n_t_types <- 5

dgp_names_old <- c("graph1", "graph2", "graph3", "graph4", "graph5")
dgp_names_narrow <- c("narrow_graph3", "narrow_graph4", "narrow_graph5")
dgp_names_wide <- c("graph3", "graph4", "graph5")
dgp_names <- c(dgp_names_narrow, dgp_names_wide)

change_names <- c("noise0.2", "const0.05", "const0.1", "const0.15")
change_names <- c("truegraph", "change1.4", "change1.6",
                  "noise0.1", "noise0.2", "noise0.3", 
                  "const0.05", "const0.1", "const0.15",
                  "permute134256")
change_names <- c("truegraph", "change1.4", "change1.6",
                  "const0.05", "const0.1", "const0.15",
                  "permute134256")


comp_names <- c("frob","maxdiff", "l1")

comp_grid_mod <- expand.grid(mod_a = seq(1, n_ind, 1),
            mod_b = seq(1, n_ind, 1),
            dgp = dgp_names, 
            change = change_names,
            tp = n_tp,
            comp = comp_names)

# New way of creating models to be compared:
model_combs <- data.frame(
  mod_a = seq(1, n_ind, 1),
  mod_b = sample(100, 100, replace = FALSE)
)

comp_grid_prep <- expand.grid(
            dgp = dgp_names, 
            change = change_names,
            tp = n_tp,
            comp = comp_names)

comp_grid_mod <- merge(model_combs, comp_grid_prep)

# Filter redundant comparisons within truegraph
# comp_grid_mod <- comp_grid_mod %>% 
#   filter(!c(mod_a == mod_b & change == "truegraph")) 


# Mutate to correct format
comp_grid_mod <- comp_grid_mod %>% 
        mutate(dgp = as.character(dgp),
           change = as.character(change),
           tp = as.numeric(as.character(tp)),
           comp = as.character(comp))
  

# Number of comparison combinations
n_c_comb <- nrow(comp_grid_mod)

```


## Compare models 
Previous model objects became too large, now we read them in instead of keeping them in memory.
```{r}
comp_grid <- expand.grid(dgp = dgp_names, 
                         change = change_names, 
                         comp = comp_names,
                         tp = n_tp)
  
# Add filenames
comp_grid <- comp_grid %>% 
  mutate(ref_file = paste0("fit_", dgp, "_","truegraph","_",tp,".RDS"),
         comp_file = paste0("fit_", dgp, "_",change,"_",tp,".RDS"))


# Add filenames
comp_grid <- comp_grid %>% 
  mutate(ref_file = paste0("fit_", dgp, "_","truegraph","_",tp,".RDS"),
         comp_file = paste0("fit_", dgp, "_",change,"_",tp,".RDS"))


############################# NOT MUCH MORE THAN 3!!!!!!!!!!!!
before_comp <- Sys.time()
ncores <- 6
cl <- makeCluster(ncores)
clusterExport(cl, c("comp_grid",  "comp_grid_mod", "here", "compare_gvar_between", "post_distance_between"))
clusterEvalQ(cl, library(tidyverse))
clusterEvalQ(cl, library(tsnet))

# todo change back to 1:nrow(comp_grid)
parLapply(cl = cl, 1:nrow(comp_grid), function(n){
  ## Get filter args
  dgp_it <- as.character(comp_grid$dgp[n])
  change_it <- as.character(comp_grid$change[n])
  tp_it <- as.numeric(as.character(comp_grid$tp[n]))
  comp_it <- as.character(comp_grid$comp[n])
  
  
  
  ## Read files
  # do not use here() because of linux server
  l_ref <- readRDS(file = paste0("~/HDD/var-compare/data/", comp_grid$ref_file[n]))
  l_ref <- l_ref[c(1:100)]
  l_comp <- readRDS(file = paste0("~/HDD/var-compare/data/", comp_grid$comp_file[n]))
  l_comp <- l_comp[c(1:100)]  
    


  ## Perform comparison 
  # Loop over all possible model combinations
  comp_ind <- comp_grid_mod %>% 
    filter(dgp == dgp_it &
           change == change_it &
           tp == tp_it &
           comp == comp_it)
  

  wc_res <- list()
  wc_res  <- lapply(c(1:nrow(comp_ind)), function(x){
    
    ## Get fitting args
    ma <- as.numeric(as.character(comp_ind$mod_a[x]))
    mb <- as.numeric(as.character(comp_ind$mod_b[x]))
    cmp <- as.character(comp_ind$comp[x])
    
    wc_res[[x]] <- list()
    
    
    # no need to save the "comp" argument in the results, bc it is in the file name
    wc_res[[x]] <- compare_gvar_between(fit_a = l_ref[[ma]],
                                        fit_b = l_comp[[mb]],
                                        comp = cmp, 
                                        n_draws = 1000,
                                        combine_post = FALSE,
                                        sampling_method = "random",
                                        burnin = 500
                                                  )
    
  })
  
  # Save output
  saveRDS(wc_res, file = here::here(paste0("data/revision1/compare_sim_res/comp_",dgp_it, "_",change_it,"_", tp_it, "_",comp_it, ".RDS")))
  
})

stopCluster(cl)
after_comp <- Sys.time()-before_comp   # ~6 hours



# check if all relevant files are present
exist_files <- list.files(path = here::here("data/revision1/compare_sim_res/"))

desired_files <- vector(length = nrow(comp_grid))
desired_files <- data.frame(filename = rep(NA, nrow(comp_grid)),
                            rownum = seq(1,nrow(comp_grid), by = 1))
# desired_files <- list()
for(n in 1:nrow(comp_grid)){

  dgp_it <- as.character(comp_grid$dgp[n])
  change_it <- as.character(comp_grid$change[n])
  tp_it <- as.numeric(as.character(comp_grid$tp[n]))
  comp_it <- as.character(comp_grid$comp[n])
  
  desired_files[n,1]<- paste0("comp_", dgp_it, "_",change_it,"_", tp_it, "_",comp_it, ".RDS")
}
# Find files that were not created yet
todo_files <- setdiff(desired_files$filename, exist_files)
todo_files_num <- desired_files %>% 
  filter(!filename %in% exist_files) %>% 
  pull(rownum)
todo_files_num
# This then has to be passed back to the loop above

# Delete graph4 change1.2 
todo_files <- todo_files[-grep("graph1", todo_files)]

todo_files_num <- desired_files %>% 
  filter(!filename %in% exist_files) %>% 
  filter(!grepl("graph5_noise0.2", filename)) %>% 
  pull(rownum)

todo_files <- todo_files[grep("graph5", todo_files)]
todo_files_num <- desired_files %>% 
  filter(!filename %in% exist_files) %>% 
  filter(grepl("graph5", filename)) %>% 
  pull(rownum)

```


For server: Moving files to HDD
```{r}
l_copy <- list.files(path = here::here("data/compare_sim_res"), pattern = "comp_graph5")
file.copy(from = paste0(here::here("data/compare_sim_res/"), l_copy),
          to = paste0("/home/bjoern/HDD/var-compare/data/compare_sim_res/", l_copy))

file.remove(from = paste0(here::here("data/compare_sim_res/"), l_copy))

```

## Computing empirical matrix differences
For each condition, compute the means and SDs of the distance distributions.

Small helper function: 
```{r}
calculate_stats <- function(x) {
  unlist(lapply(x, function(subelement) {
    c(mean = mean(subelement), sd = sd(subelement))
  }))

}

```



```{r}
file_list <- list.files(path = here::here("data/revision1/compare_sim_res"))

time_before_within_eval <- Sys.time()
ncores = 45
cl = makeCluster(ncores)
registerDoParallel(cl)
l_comp_res <- list()
l_comp_res <- foreach(i = 1:length(file_list)) %dopar% {
  comp_res <- readRDS(here::here(paste0("data/revision1/compare_sim_res/",file_list[i])))
  
  ## Obtain information from filename
  file_str <- file_list[i]
  file_str_split <- strsplit(file_str, split = "_")
  # for non-narrow condition
  if(length(file_str_split[[1]]) == 5){
  dgp_it <- file_str_split[[1]][2]
  change_it <- file_str_split[[1]][3]
  tp_it <- file_str_split[[1]][4]
  comp_it <- file_str_split[[1]][5]
  # delete file ending 
  comp_it <- gsub("\\..*", "", comp_it)
  }
  # for narrow condition
  if(length(file_str_split[[1]]) == 6){
  dgp_it <- paste(file_str_split[[1]][2], file_str_split[[1]][3], sep = "_")
  change_it <- file_str_split[[1]][4]
  tp_it <- file_str_split[[1]][5]
  comp_it <- file_str_split[[1]][6]
  # delete file ending 
  comp_it <- gsub("\\..*", "", comp_it)
  }

  ## Evaluation
  # Loop over all comparisons
  eval_res <- list()
  eval_res <- lapply(comp_res,calculate_stats)
  eval_res <- as.data.frame(do.call(rbind, eval_res))
  eval_res$dgp <- dgp_it
  eval_res$change <- change_it
  eval_res$tp <- tp_it
  eval_res$comp <- comp_it

  print(paste0("File ", i, " done!"))
  
  # Save output
  saveRDS(eval_res, file = here::here(paste0("data/revision1/norm_distributions/norms_",dgp_it, "_",change_it,"_", tp_it, "_",comp_it, ".RDS")))
  
}
stopCluster(cl)



```

Read them in again and combine them: 
```{r}
file_list_norms <- list.files(path = here::here("data/revision1/norm_distributions"))

norm_files <- list()
for(i in 1:length(file_list_norms)){
  norm_files[[i]] <- readRDS(here::here(paste0("data/revision1/norm_distributions/", file_list_norms[i])))
}

# df_norms_both contains both a and b (without combination)
df_norms <- do.call(rbind, norm_files)
# saveRDS(df_norms, file = here("data/revision1/norm_distributions/df_norms_both.RDS"))
df_norms <- readRDS(here("data/revision1/norm_distributions/df_norms_both.RDS"))
```

### Plot the empirical norms

```{r}
# first only look at the narrow priors
plot_norms_mean <- df_norms %>% 
  # filter dgp column, should contain "narrow"
  filter(grepl("narrow", dgp)) %>%
  mutate(dgp = as.factor(dgp), 
         change = as.factor(change),
         tp = as.factor(tp),
         comp = as.factor(comp)) %>%
  mutate(tp = forcats::fct_relevel(tp, "50", "100", "200", "400", "1000")) %>% 
  pivot_longer(cols = c(contains("mean"), contains("sd")), 
               names_to = "stat", values_to = "value") %>% 
  mutate(stat = case_when(
    grepl("beta.mean", stat) ~ "beta_post.mean",
    grepl("beta.sd", stat) ~ "beta_post.sd",
    grepl("pcor.mean", stat) ~ "pcor_post.mean",
    grepl("pcor.sd", stat) ~ "pcor_post.sd",
    .default = stat
  )) %>% 
  separate(stat, into = c("mat", "stat"), sep = c("\\.")) %>% 
  separate(mat, into = c("mat", "type"), sep = c("_")) %>% 
  filter(stat == "mean") %>% 
  ggplot(aes(x = tp, y = value, fill = type, width = after_stat(density))) +
  ggridges::geom_vridgeline(stat="ydensity") + 
  ggh4x::facet_nested(change ~ dgp + mat)+
  theme_compare()+
  ggokabeito::scale_fill_okabe_ito(order = c(5,1:8))

ggsave(here::here("figures/revision1/empirical_norms_narrow_mean.svg"), plot = plot_norms_mean, width = 20, height = 10)

```


Table them
```{r}
df_norms %>% 
  mutate(dgp = as.factor(dgp), 
         change = as.factor(change),
         tp = as.factor(tp),
         comp = as.factor(comp)) %>%
  mutate(tp = forcats::fct_relevel(tp, "50", "100", "200", "400", "1000")) %>% 
  arrange(tp, change, comp) %>% 
  pivot_longer(cols = c(contains("mean"), contains("sd")), 
               names_to = "stat", values_to = "value") %>% 
  mutate(stat = case_when(
    grepl("beta.mean", stat) ~ "beta_post_ab.mean",
    grepl("beta.sd", stat) ~ "beta_post_ab.sd",
    grepl("pcor.mean", stat) ~ "pcor_post_ab.mean",
    grepl("pcor.sd", stat) ~ "pcor_post_ab.sd",
    .default = stat
  )) %>% 
  separate(stat, into = c("mat", "stat"), sep = c("\\.")) %>% 
  separate(mat, into = c("mat", "type", "net"), sep = c("_")) %>% 
  select(!type) %>% 
  group_by(dgp, change, tp, comp, mat) %>% 
  pivot_wider(names_from = c(stat,net), values_from = value, values_fn = mean) %>% 
  # round every column that contains "mean" or "sd" to three digits
  mutate(across(matches("mean|sd"), ~round(., digits = 3))) %>%
  gt(groupname_col = "dgp") %>% 
  gt_theme_538() %>% 
  gtsave(here::here("figures/revision1/empirical_norms_mean_ab.html"))


```

Check how often the mean in each condition is larger than the reference mean

```{r}
df_norms %>% 
  mutate(dgp = as.factor(dgp), 
         change = as.factor(change),
         tp = as.factor(tp),
         comp = as.factor(comp)) %>%
  mutate(tp = forcats::fct_relevel(tp, "50", "100", "200", "400", "1000")) %>% 
  arrange(tp, change, comp) %>% 
  pivot_longer(cols = c(contains("mean"), contains("sd")), 
               names_to = "stat", values_to = "value") %>% 
  mutate(stat = case_when(
    grepl("beta.mean", stat) ~ "beta_post_ab.mean",
    grepl("beta.sd", stat) ~ "beta_post_ab.sd",
    grepl("pcor.mean", stat) ~ "pcor_post_ab.mean",
    grepl("pcor.sd", stat) ~ "pcor_post_ab.sd",
    .default = stat
  )) %>% 
  separate(stat, into = c("mat", "stat"), sep = c("\\.")) %>% 
  separate(mat, into = c("mat", "type", "net"), sep = c("_")) %>% 
  filter(stat == "mean") %>%
  select(!stat) %>% 
  group_by(dgp, change, tp, comp, mat, type, net) %>% 
  mutate(id = row_number()) %>% 
  pivot_wider(names_from = c(type, net), values_from = value) %>%
  rename(post = post_ab) %>% 
  mutate(diff = ifelse(post > ref_a | post > ref_b , 1, 0)) %>% 
  group_by(dgp, change, tp, comp, mat) %>%
  summarize(pct_detect = mean(diff)) %>%
  pivot_wider(names_from = mat, values_from = pct_detect) %>% 
  gt(groupname_col = "dgp") %>% 
  gt_theme_nytimes() %>% 
  tab_header(
    title = "Proportion of simulations where the posterior mean is larger than the reference mean"
  ) %>% 
  gt_color_rows(
    columns = c(beta, pcor), 
    palette = c("#CC79A7", "#009E73"),
    domain = c(0, 1)
  ) %>%  
  gtsave(here::here("figures/revision1/empirical_norms_mean_diff_detect_ab.html"))
  


```



### Plot example norm distributions

Large sample, same DGP, wide prior: 
```{r}
cgt <- readRDS("~/var-compare/data/revision1/compare_sim_res/comp_graph4_truegraph_1000_frob.RDS")

posterior_df <- data.frame()
for (i in 1:length(cgt)) {
  element <- cgt[[i]]
  
  # Extract relevant vectors and create a data frame
  element_df <- data.frame(
    sample = rep(i, each = length(element$beta_ref_a)),
    beta_ref_a = element$beta_ref_a,
    beta_ref_b = element$beta_ref_b,
    beta = element$beta
  )
  
  # Append the data frame to the main data frame
  posterior_df <- rbind(posterior_df, element_df)
}
posterior_long <- posterior_df %>%
  pivot_longer(cols = c(beta_ref_a, beta_ref_b, beta), names_to = "parameter")

example_elements <- sample(1:length(cgt), 10)
example_data <- filter(posterior_long, sample %in% example_elements)

ggplot(example_data, aes(x = value, fill = parameter)) +
  geom_density(alpha = 0.5) +
  facet_wrap(~ sample, scales = "free") +
  theme_minimal() +
  labs(title = "Density Plots of Posterior Distributions for same DGP")

# Test what happens if I subtract the equivalence range
p <- 6
equiv_range <- 0.01 * (p * p)
example_data %>% 
  mutate(value = if_else(parameter == "beta", value - equiv_range, value)) %>% 
  ggplot(aes(x = value, fill = parameter)) +
  geom_density(alpha = 0.5) +
  facet_wrap(~ sample, scales = "free") +
  theme_minimal() +
  labs(title = "Density Plots of Posterior Distributions for same DGP")

posterior_df %>%
  mutate(beta = beta - equiv_range) %>%
  group_by(sample) %>%
  summarize(overlap = as.numeric(bayestestR::overlap(beta_ref_a, beta)),
            p_sup = as.numeric(effectsize::p_superiority(beta, beta_ref_a)$p_superiority))



```

Same DGP, low sample size: 
```{r}
cgt <- readRDS("~/var-compare/data/revision1/compare_sim_res/comp_graph4_truegraph_50_frob.RDS")

posterior_df <- data.frame()
for (i in 1:length(cgt)) {
  element <- cgt[[i]]
  
  # Extract relevant vectors and create a data frame
  element_df <- data.frame(
    sample = rep(i, each = length(element$beta_ref_a)),
    beta_ref_a = element$beta_ref_a,
    beta_ref_b = element$beta_ref_b,
    beta = element$beta
  )
  
  # Append the data frame to the main data frame
  posterior_df <- rbind(posterior_df, element_df)
}
posterior_long <- posterior_df %>%
  pivot_longer(cols = c(beta_ref_a, beta_ref_b, beta), names_to = "parameter")

example_elements <- sample(1:length(cgt), 10)
example_data <- filter(posterior_long, sample %in% example_elements)

ggplot(example_data, aes(x = value, fill = parameter)) +
  geom_density(alpha = 0.5) +
  facet_wrap(~ sample, scales = "free") +
  theme_minimal() +
  labs(title = "Density Plots of Posterior Distributions for same DGP")

# Test what happens if I subtract the equivalence range
p <- 6
equiv_range <- 0.03 * (p * p)
example_data %>% 
  mutate(value = if_else(parameter == "beta", value - equiv_range, value)) %>% 
  ggplot(aes(x = value, fill = parameter)) +
  geom_density(alpha = 0.5) +
  facet_wrap(~ sample, scales = "free") +
  theme_minimal() +
  labs(title = "Density Plots of Posterior Distributions for same DGP")


# Quantify the overlap
posterior_df %>%
  mutate(beta = beta - equiv_range) %>%
  group_by(sample) %>%
  summarize(overlap = as.numeric(bayestestR::overlap(beta_ref_a, beta)),
            p_sup = effectsize::p_superiority(beta, beta_ref_a)$p_superiority)
```

What happens for true differences?
```{r}
cgt <- readRDS("~/var-compare/data/revision1/compare_sim_res/comp_graph4_const0.15_1000_frob.RDS")

posterior_df <- data.frame()
for (i in 1:length(cgt)) {
  element <- cgt[[i]]
  
  # Extract relevant vectors and create a data frame
  element_df <- data.frame(
    sample = rep(i, each = length(element$beta_ref_a)),
    beta_ref_a = element$beta_ref_a,
    beta_ref_b = element$beta_ref_b,
    beta = element$beta
  )
  
  # Append the data frame to the main data frame
  posterior_df <- rbind(posterior_df, element_df)
}
posterior_long <- posterior_df %>%
  pivot_longer(cols = c(beta_ref_a, beta_ref_b, beta), names_to = "parameter")

example_elements <- sample(1:length(cgt), 10)
example_data <- filter(posterior_long, sample %in% example_elements)

ggplot(example_data, aes(x = value, fill = parameter)) +
  geom_density(alpha = 0.5) +
  facet_wrap(~ sample, scales = "free") +
  theme_minimal() +
  labs(title = "Density Plots of Posterior Distributions for same DGP")

# Test what happens if I subtract the equivalence range
p <- 6
equiv_range <- 0.05 * (p * p)
example_data %>% 
  mutate(value = if_else(parameter == "beta", value - equiv_range, value)) %>% 
  ggplot(aes(x = value, fill = parameter)) +
  geom_density(alpha = 0.5) +
  facet_wrap(~ sample, scales = "free") +
  theme_minimal() +
  labs(title = "Density Plots of Posterior Distributions for different DGP")


# Quantify the overlap
posterior_df %>%
  mutate(beta = beta - equiv_range) %>%
  group_by(sample) %>%
  summarize(overlap = as.numeric(bayestestR::overlap(beta_ref_a, beta)),
            p_sup = as.numeric(effectsize::p_superiority(beta, beta_ref_a)$p_superiority))
```


Write the comparison into a function: 
```{r}
overlap_posterior <- function(comp_obj, 
                              equiv_range_beta = 0,
                              equiv_range_pcor = 0,
                              # Should within posterior uncertainty of A and B be combined?
                              combine_posteriors = TRUE,
                              nvar = 6) {
  
  # browser()
  
  overlap_df <- data.frame(beta = comp_obj$beta,
                           pcor = comp_obj$pcor) 
  n_samples <- length(comp_obj$beta_ref_a)
  
  if(isTRUE(combine_posteriors)){
     overlap_df$beta_ref <- c(
                          comp_obj$beta_ref_a[sample(1:n_samples, n_samples/2)], 
                          comp_obj$beta_ref_b[sample(1:n_samples, n_samples/2)])
     overlap_df$pcor_ref <- c(
                          comp_obj$pcor_ref_a[sample(1:n_samples, n_samples/2)], 
                          comp_obj$pcor_ref_b[sample(1:n_samples, n_samples/2)])
     
  } else {
    stop("Comparing against two distributions is not implemented yet.")
  }
  
  
  # Quantify the overlap
  erb <- equiv_range_beta * (nvar * nvar)
  erp <- equiv_range_pcor * ((nvar * nvar)/2 - nvar/2)
  
  res_df <- overlap_df %>%
    dplyr::mutate(
           beta = beta - erb,
           pcor = pcor - erp) %>%
    dplyr::summarize(
              overlap_beta = as.numeric(bayestestR::overlap(beta_ref, beta)),
              sup_beta = as.numeric(effectsize::p_superiority(beta, 
                                                              beta_ref, 
                                                              parametric = FALSE)$p_superiority),
              overlap_pcor = as.numeric(bayestestR::overlap(pcor_ref, pcor)),
              sup_pcor = as.numeric(effectsize::p_superiority(pcor, 
                                                              pcor_ref,
                                                              parametric = FALSE)$p_superiority))
  
  return(res_df)
  
}

```






## Testing the differences
Reading the files in again and extracting summary information for each
```{r}
file_list <- list.files(path = here::here("data/revision1/compare_sim_res"))

time_before_within_eval <- Sys.time()
# DONT GO TOO HIGH HERE!!! FILES BECOME TOO LARGE
# (had to go with capslock because I forgot too often)
ncores = 50
cl = makeCluster(ncores)
registerDoParallel(cl)
clusterExport(cl, c("overlap_posterior"))
clusterEvalQ(cl, library(tidyverse))
clusterEvalQ(cl, library(effectsize))
clusterEvalQ(cl, library(bayestestR))
l_comp_res <- list()
l_comp_res <- foreach(i = 1:length(file_list)) %dopar% {
  comp_res <- readRDS(here::here(paste0("data/revision1/compare_sim_res/",file_list[i])))
  
  ## Obtain information from filename
  file_str <- file_list[i]
  file_str_split <- strsplit(file_str, split = "_")
  # for non-narrow condition
  if(length(file_str_split[[1]]) == 5){
  dgp_it <- file_str_split[[1]][2]
  change_it <- file_str_split[[1]][3]
  tp_it <- file_str_split[[1]][4]
  comp_it <- file_str_split[[1]][5]
  # delete file ending 
  comp_it <- gsub("\\..*", "", comp_it)
  }
  # for narrow condition
  if(length(file_str_split[[1]]) == 6){
  dgp_it <- paste(file_str_split[[1]][2], file_str_split[[1]][3], sep = "_")
  change_it <- file_str_split[[1]][4]
  tp_it <- file_str_split[[1]][5]
  comp_it <- file_str_split[[1]][6]
  # delete file ending 
  comp_it <- gsub("\\..*", "", comp_it)
  }

  ## Evaluation
  # Loop over all comparisons
  eval_res <- list()
  eval_res <- lapply(comp_res, function(x){
    
    res00 <- overlap_posterior(x,
                              equiv_range_beta = 0,
                              equiv_range_pcor = 0,
                              combine_posteriors = TRUE)
    res00$equiv_range <- 0
    
    res01 <- overlap_posterior(x,
                             equiv_range_beta = 0.01,
                             equiv_range_pcor = 0.01,
                             combine_posteriors = TRUE)   
    res01$equiv_range <- 0.01
    
    res05 <- overlap_posterior(x,
                             equiv_range_beta = 0.05,
                             equiv_range_pcor = 0.05,
                             combine_posteriors = TRUE)   
    res05$equiv_range <- 0.05
    
    res <- rbind(res00, res01, res05)
    
    res$dgp <- dgp_it
    res$change <- change_it
    res$tp <- tp_it
    res$comp <- comp_it

    return(res)
  })
  
  
  ## Output
  # Combine all results into dataframe
  df_eval_res <- do.call(rbind.data.frame, eval_res)
  print(paste0("File ", i, " done!"))
  
  # Save output
  saveRDS(df_eval_res, file = here::here(paste0("data/revision1/overlap_res/overlap_res_",dgp_it, "_",change_it,"_", tp_it, "_",comp_it, ".RDS")))
  
}
stopCluster(cl)

time_after_within_eval <- Sys.time() - time_before_within_eval  

# df_comp_res <- do.call(rbind, l_comp_res)
# write_rds(df_comp_res, "df_comp_res.RDS")


# Check which files are missing
# exist_files_res <- list.files(path = here::here("data/compare_sim_res"))
# exist_files_eval <- list.files(path = here::here("data/compare_sim_eval"))
# desired_files <- gsub("comp", "eval_res",exist_files_res)
# 
# desired_files <- setdiff(desired_files, exist_files_eval)
# file_list <- gsub("eval_res", "comp",desired_files)

# This then has to be passed back to the loop above
# to_del <- list.files(path = here::here("data/compare_sim_eval/"), pattern = "narrow")
# file.remove(from = paste0(here::here("data/compare_sim_eval/"), to_del))


```


Read in results again, they were saved as individual files. 
```{r}
# For wide priors
file_list <- list.files(path = here("data/revision1/overlap_res"), full.names = TRUE)
file_list_w <- file_list[-grep("_narrow_", file_list)]
l_comp_res_w <- lapply(file_list_w, readRDS)
df_comp_res_w <- do.call(rbind, l_comp_res_w)


# For narrow priors
file_list <- list.files(path = here("data/revision1/overlap_res"), full.names = TRUE)
file_list_n <- file_list[grep("_narrow_", file_list)]
l_comp_res_n <- lapply(file_list_n, readRDS)
df_comp_res_n <- do.call(rbind, l_comp_res_n)


# Combine both 
df_comp_res_w$prior <- rep("wide", nrow(df_comp_res_w))
df_comp_res_n$prior <- rep("narrow", nrow(df_comp_res_n))

df_comp_res <- rbind(df_comp_res_w, df_comp_res_n)

# write_rds(df_comp_res, here::here("output/revision1/df_overlap_res.RDS"))
df_overlap_res <- read_rds(here::here("output/revision1/df_overlap_res.RDS"))

```


# Investigate Overlap metrics
Prep
```{r}
change_names <- c("change1.4" = paste("Largest", "\u00D7", "1.4"),
                  "change1.6" = paste("Largest", "\u00D7", "1.6"),
                  "const0.05" = paste("All", "\u00b1", "0.05"),
                  "const0.1" = paste("All", "\u00b1", "0.10"),
                  "const0.15" = paste("All", "\u00b1", "0.15"),
                  "permute" = "Permute",
                  "truegraph" = "Same DGP"
)

graph_names <- c("Empirical\nSparse" = "graph3",
                 "Simulated\nChain" = "graph4",
                 "Simulated\nNonsparse" = "graph5")

norm_names <- c("frob" = "Frobenius",
                "l1" = "\u2113[1]",
                "maxdiff" = "Maxdiff")

tp_levels <- c("50" = "1", "100" = "2", "200" = "3", "400" = "4", "1000" = "5")

# plotting linetypes
cond_lty <- set_names(c(1,2),
                      c("narrow", "wide"))

df_overlap <- df_overlap_res %>% 
  mutate(tp = as.factor(tp)) %>% 
      mutate(tp = forcats::fct_relevel(tp, "50", "100", "200", "400", "1000")) %>% 
      dplyr::mutate(dgp = fct_recode(as_factor(as.character(dgp)), !!!graph_names)) %>% 
      dplyr::mutate(change = case_match(
            change,
                  "change1.4" ~ paste("Largest", "\u00D7", "1.4"),
                  "change1.6" ~ paste("Largest", "\u00D7", "1.6"),
                  "const0.05" ~ paste("All", "\u00b1", "0.05"),
                  "const0.1" ~ paste("All", "\u00b1", "0.10"),
                  "const0.15" ~ paste("All", "\u00b1", "0.15"),
                  "permute134256" ~ "Permute",
                  "truegraph" ~ "Same DGP"
          )) %>% 
          dplyr::mutate(change = as.factor(change)) %>% 
          dplyr::mutate(change = forcats::fct_relevel(change, 
                                                      "Same DGP",
                                                      "Largest × 1.4", 
                                                      "Largest × 1.6",
                                                      "All ± 0.05",
                                                      "All ± 0.10",
                                                      "All ± 0.15",
                                                      "Permute")) %>% 

  mutate(equiv_range = as.factor(equiv_range)) %>% 
  pivot_longer(cols = c(overlap_beta, sup_beta, overlap_pcor, sup_pcor), 
               names_to = "metric", values_to = "value") %>%
  separate(metric, into = c("metric", "matrix"), sep = "_") %>% 
    mutate(matrix = case_match(
    matrix,
    "beta" ~ "Temporal",
    "pcor" ~ "Contemporaneous"
  ))
  

```





## Plot superiority
Look at superiority
```{r}
plot_superiority <- df_overlap %>%
  # filter(prior == "wide") %>% 
  filter(metric == "sup") %>% 
  filter(comp == "frob") %>% 
  filter(matrix == "Temporal") %>% 
  ggplot(aes(x = tp, y = value, color = equiv_range)) + 
  geom_boxplot() + 
  theme_compare()  + 
  facet_nested(change ~ prior + dgp) + 
  ggokabeito::scale_color_okabe_ito(order = c(5, 1:8))+
  geom_vline(colour = "#F3F4F5", xintercept = seq(1.5, length(tp_levels), 1))+
  theme(panel.grid.major.x = element_blank())+
  labs(caption = "Wide prior,  superiority.")
  
  

ggsave(here::here("figures/revision1/plot_superiority_temporal_frob.pdf"), width = 15, height = 20)

```


Only look at it within the partial correlations, where the method does not seem to work well (due to an error, as we now know).
```{r}
overlapsup_pcor <- df_overlap %>% 
  filter(matrix == "Contemporaneous") %>%
  ggplot(aes(x = tp, y = value, color = equiv_range)) +
  geom_boxplot() +
  theme_compare()  +
  facet_nested(comp + change ~ metric + dgp) +
  ggokabeito::scale_color_okabe_ito(order = c(5, 1:8))+
  geom_vline(colour = "#F3F4F5", xintercept = seq(1.5, length(tp_levels), 1))+
  theme(panel.grid.major.x = element_blank())

ggsave(here::here("figures/revision1/plot_overlapsup_pcor.pdf"), width = 15, height = 20)



```




## Create arbitrary decision rule
Try out arbitrary decision rules to see how well the overlap and superiority metrics work.
```{r}
dec_rule_overlap <- df_overlap %>% 
  group_by(equiv_range, dgp, change, tp, comp, prior, matrix) %>% 
  pivot_wider(names_from = metric, values_from = value, values_fn = list) %>%
  unnest(cols = c(overlap, sup)) %>% 
  mutate(decision = case_when(
    overlap < 0.25 & sup > 0.5 ~ 1,
    .default = 0
  )) %>% 
  summarize(edr = mean(decision)) %>% 
  ggplot(aes(x = tp, y = edr, color = equiv_range)) +
  geom_point() +
  theme_compare()  +
  facet_nested(comp + change ~ matrix + dgp) +
  ggokabeito::scale_color_okabe_ito(order = c(5, 1:8))+
  geom_vline(colour = "#F3F4F5", xintercept = seq(1.5, length(tp_levels), 1))+
  theme(panel.grid.major.x = element_blank())

ggsave(here::here("figures/revision1/plot_dec_rule_overlap.pdf"), width = 15, height = 20)

``` 






# Old Code Revised: Rerun Simulation 2 with some changes
This is the code for the revised version of the manuscript, in which we combine the reference distributions into a single reference distribution. 

```{r}
# Setup list of conditions
# number of data-generating processes
n_dgp <- 5
# Number of comparison types
n_c_types <- 3

# Number of different graph structures
n_g_types <- 9

# Number of different tp conditions
n_t_types <- 5

dgp_names <- c("graph1", "graph2", "graph3", "graph4", "graph5")


# Switch between these for narrow vs. wide prior
dgp_names_n <- c("narrow_graph3", "narrow_graph4", "narrow_graph5")
dgp_names_w <- c("graph3", "graph4", "graph5")
dgp_names <- c(dgp_names_n, dgp_names_w)

change_names <- c("noise0.2", "const0.05", "const0.1", "const0.15")
change_names <- c("truegraph", "change1.4", "change1.6",
                  "noise0.1", "noise0.2", "noise0.3",
                  "const0.05", "const0.1", "const0.15",
                  "permute134256")

comp_names <- c("frob","maxdiff", "l1")

# New way of creating models to be compared:
model_combs <- data.frame(
  mod_a = seq(1, n_ind, 1),
  mod_b = sample(100, 100, replace = FALSE)
)

generate_unique_pairs <- function(n, count) {
  all_combinations <- combn(1:n, 2, simplify = TRUE)
  
  # Randomly shuffle columns
  shuffled_combinations <- all_combinations[, sample(ncol(all_combinations))]
  
  # Select the first 'count' columns
  selected_combinations <- shuffled_combinations[, 1:count]
  
  # Create a data frame from the selected combinations
  model_combs <- data.frame(
    mod_a = selected_combinations[1, ],
    mod_b = selected_combinations[2, ]
  )
  
  # Optional: Sort each row
  model_combs <- t(apply(model_combs, 1, sort))
  model_combs <- as.data.frame(model_combs)
  
  return(model_combs)
}
model_combs <- generate_unique_pairs(n = 100, count = 500)



comp_grid_prep <- expand.grid(
            dgp = dgp_names, 
            change = change_names,
            tp = n_tp,
            comp = comp_names)

comp_grid_mod <- merge(model_combs, comp_grid_prep)

# Filter redundant comparisons within truegraph
# comp_grid_mod <- comp_grid_mod %>% 
#   filter(!c(mod_a == mod_b & change == "truegraph")) 


# Mutate to correct format
comp_grid_mod <- comp_grid_mod %>% 
        mutate(dgp = as.character(dgp),
           change = as.character(change),
           tp = as.numeric(as.character(tp)),
           comp = as.character(comp))

# Number of comparisons
nrow(comp_grid_mod)

```


## Compare models 
Previous model objects became too large, now we read them in instead of keeping them in memory.
```{r}
comp_grid <- expand.grid(dgp = dgp_names, 
                         change = change_names, 
                         comp = comp_names,
                         tp = n_tp)
  
# Add filenames
comp_grid <- comp_grid %>% 
  mutate(ref_file = paste0("fit_", dgp, "_","truegraph","_",tp,".RDS"),
         comp_file = paste0("fit_", dgp, "_",change,"_",tp,".RDS"))




############################# NOT MORE THAN 5!!!!!!!!!!!!
before_comp <- Sys.time()
ncores <- 5
cl <- makeCluster(ncores)
clusterExport(cl, c("comp_grid",  "comp_grid_mod", "within_compare", "post_distance_within", "here"))
clusterEvalQ(cl, library(tidyverse))

# todo change back to 1:nrow(comp_grid)
parLapply(cl = cl, 1:nrow(comp_grid), function(n){
  ## Get filter args
  dgp_it <- as.character(comp_grid$dgp[n])
  change_it <- as.character(comp_grid$change[n])
  tp_it <- as.numeric(as.character(comp_grid$tp[n]))
  comp_it <- as.character(comp_grid$comp[n])
  
  
  
  ## Read files
  l_ref <- readRDS(file = paste0("~/HDD/var-compare/data/", comp_grid$ref_file[n]))
  l_ref <- l_ref[c(1:100)]
  l_ref <- lapply(l_ref, function(x){
    x$fit$fisher_z <- NULL
    return(x)
  })
  l_comp <- readRDS(file = paste0("~/HDD/var-compare/data/", comp_grid$comp_file[n]))
  l_comp <- l_comp[c(1:100)]
  l_comp <- lapply(l_comp, function(x){
    x$fit$fisher_z <- NULL
    return(x)
  })
    
    


  ## Perform comparison 
  # Loop over all possible model combinations
  comp_ind <- comp_grid_mod %>% 
    mutate(dgp = as.character(dgp),
           change = as.character(change),
           tp = as.numeric(as.character(tp)),
           comp = as.character(comp)) %>% 
    filter(dgp == dgp_it &
           change == change_it &
           tp == tp_it &
           comp == comp_it)
  

  wc_res <- list()
  wc_res  <- lapply(c(1:nrow(comp_ind)), function(x){
    
    ## Get fitting args
    ma <- as.numeric(as.character(comp_ind$mod_a[x]))
    mb <- as.numeric(as.character(comp_ind$mod_b[x]))
    cmp <- as.character(comp_ind$comp[x])
    
    wc_res[[x]] <- list()
    wc_res[[x]] <- tryCatch({within_compare(mod_a = ma,
                      mod_b = mb,
                      fitpost_a = l_ref,
                      fitpost_b = l_comp,
                      fitemp_a = l_ref,
                      fitemp_b = l_comp,
                      n_draws = 1000,
                      comparison = cmp,
                      postpred = FALSE)}, error = function(e) NA)
  })
  
  # Save output
  saveRDS(wc_res, file = here::here(paste0("data/revision1/compare_sim_res_old_idea/comp_",dgp_it, "_",change_it,"_", tp_it, "_",comp_it, ".RDS")))
  # print(paste0("Just finished row", n))
  
})

stopCluster(cl)
after_comp <- Sys.time()-before_comp



# check if all relevant files are present
exist_files <- list.files(path = here::here("data/revision1/compare_sim_res_old_idea"))

desired_files <- vector(length = nrow(comp_grid))
desired_files <- data.frame(filename = rep(NA, nrow(comp_grid)),
                            rownum = seq(1,nrow(comp_grid), by = 1))
# desired_files <- list()
for(n in 1:nrow(comp_grid)){

  dgp_it <- as.character(comp_grid$dgp[n])
  change_it <- as.character(comp_grid$change[n])
  tp_it <- as.numeric(as.character(comp_grid$tp[n]))
  comp_it <- as.character(comp_grid$comp[n])
  
  desired_files[n,1]<- paste0("comp_", dgp_it, "_",change_it,"_", tp_it, "_",comp_it, ".RDS")
}
# Find files that were not created yet
todo_files <- setdiff(desired_files$filename, exist_files)
todo_files_num <- desired_files %>% 
  filter(!filename %in% exist_files) %>% 
  pull(rownum)
todo_files_num
# This then has to be passed back to the loop above

# Delete graph4 change1.2 
todo_files <- todo_files[-grep("graph1", todo_files)]

todo_files_num <- desired_files %>% 
  filter(!filename %in% exist_files) %>% 
  filter(!grepl("graph5_noise0.2", filename)) %>% 
  pull(rownum)

todo_files <- todo_files[grep("graph5", todo_files)]
todo_files_num <- desired_files %>% 
  filter(!filename %in% exist_files) %>% 
  filter(grepl("graph5", filename)) %>% 
  pull(rownum)

```


For server: Moving files to HDD
```{r}
l_copy <- list.files(path = here::here("data/compare_sim_res"), pattern = "comp_graph5")
file.copy(from = paste0(here::here("data/compare_sim_res/"), l_copy),
          to = paste0("/home/bjoern/HDD/var-compare/data/compare_sim_res/", l_copy))

file.remove(from = paste0(here::here("data/compare_sim_res/"), l_copy))

```


Reading the files in again and extracting summary information for each
```{r}
file_list <- list.files(path = here::here("data/revision1/compare_sim_res_old_idea"))

time_before_within_eval <- Sys.time()
ncores = 5
cl = makeCluster(ncores)
registerDoParallel(cl)
clusterExport(cl, c("file_list", "within_compare_eval_rev", "post_distance_within", "here"))
l_comp_res <- foreach(i = 1:length(file_list)) %dopar% {
  comp_res <- readRDS(here::here(paste0("data/revision1/compare_sim_res_old_idea/",file_list[i])))
  
  ## Obtain information from filename
  file_str <- file_list[i]
  file_str_split <- strsplit(file_str, split = "_")
  # for non-narrow condition
  if(length(file_str_split[[1]]) == 5){
  dgp_it <- file_str_split[[1]][2]
  change_it <- file_str_split[[1]][3]
  tp_it <- file_str_split[[1]][4]
  comp_it <- file_str_split[[1]][5]
  # delete file ending 
  comp_it <- gsub("\\..*", "", comp_it)
  }
  # for narrow condition
  if(length(file_str_split[[1]]) == 6){
  dgp_it <- paste(file_str_split[[1]][2], file_str_split[[1]][3], sep = "_")
  change_it <- file_str_split[[1]][4]
  tp_it <- file_str_split[[1]][5]
  comp_it <- file_str_split[[1]][6]
  # delete file ending 
  comp_it <- gsub("\\..*", "", comp_it)
  }

  ## Evaluation
  # Loop over all comparisons
  eval_res <- list()
  eval_res <- lapply(comp_res, function(x){
    
    res <- tryCatch({within_compare_eval_rev(x)}, error = function(e) NA)
    res$dgp <- dgp_it
    res$change <- change_it
    res$tp <- tp_it
    res$comp <- comp_it
    if(is.list(x)){
      res$emp <-  x$emp[1]
    } else{
      res$emp <- NA
    }
    return(res)
  })
  
  
  ## Output
  # Combine all results into dataframe
  df_eval_res <- do.call(rbind.data.frame, eval_res)
  print(paste0("File ", i, " done!"))
  
  # Save output
  saveRDS(df_eval_res, file = here::here(paste0("data/revision1/compare_sim_eval_old_idea/eval_res_",dgp_it, "_",change_it,"_", tp_it, "_",comp_it, ".RDS")))
  
}
stopCluster(cl)

time_after_within_eval <- Sys.time() - time_before_within_eval  

# df_comp_res <- do.call(rbind, l_comp_res)
# write_rds(df_comp_res, "df_comp_res.RDS")


# Check which files are missing
exist_files_res <- list.files(path = here::here("data/compare_sim_res"))
exist_files_eval <- list.files(path = here::here("data/revision1/compare_sim_eval"))
desired_files <- gsub("comp", "eval_res",exist_files_res)

desired_files <- setdiff(desired_files, exist_files_eval)
file_list <- gsub("eval_res", "comp",desired_files)

# This then has to be passed back to the loop above
# to_del <- list.files(path = here::here("data/compare_sim_eval/"), pattern = "narrow")
# file.remove(from = paste0(here::here("data/compare_sim_eval/"), to_del))


```


Read in results again, they were saved as individual files. 
```{r}
# For wide priors
file_list <- list.files(path = here("data/revision1/compare_sim_eval_old_idea"), full.names = TRUE)
file_list_w <- file_list[-grep("_narrow_", file_list)]
l_comp_res <- lapply(file_list_w, readRDS)
df_comp_res <- do.call(rbind, l_comp_res)

write_rds(df_comp_res, here::here("data/revision1/df_comp_res_wide_old_idea_rev1.RDS"))
df_comp_res_w <- readRDS(here::here("data/revision1/df_comp_res_wide_old_idea_rev1.RDS"))

# For narrow priors
file_list <- list.files(path = here("data/revision1/compare_sim_eval_old_idea"), full.names = TRUE)
file_list_n <- file_list[grep("_narrow_", file_list)]
l_comp_res_n <- lapply(file_list_n, readRDS)
df_comp_res_n <- do.call(rbind, l_comp_res_n)


write_rds(df_comp_res_n, here::here("data/revision1/df_comp_res_narrow_old_idea_rev1.RDS"))
df_comp_res_n <- readRDS(here::here("data/revision1/df_comp_res_narrow_old_idea_rev1.RDS"))


# Combine both 
df_comp_res_w$prior <- rep("wide", nrow(df_comp_res_w))
df_comp_res_n$prior <- rep("narrow", nrow(df_comp_res_n))

df_comp_res <- rbind(df_comp_res_w, df_comp_res_n)

# write_rds(df_comp_res, here::here("output/revision1/df_comp_res_old_idea_rev1.RDS"))
df_comp_res <- readRDS(here::here("output/revision1/df_comp_res_old_idea_rev1.RDS"))


```



What do we change: 
- look at different cutoff for significance
- combine reference distributions for evaluation
  - we also have 2000 reference samples instead of 1000 now because we combine reference distributions!
- change PCOR to only look at upper.tri (not done yet)
  


Investigate nonconvergence:
```{r}
df_comp_res %>% 
  filter(is.na(emp)) %>% 
  count()    # no nonconvergence :-)

df_comp_res %>% 
  filter(is.na(emp)) %>% 
  group_by(comp, dgp, change, tp) %>% 
  count() %>% 
  View()

```


## Plotting 
General plotting preparation
```{r}
change_names <- c("change1.2" = paste("Largest", "\u00D7", "1.2"),
                  "change1.4" = paste("Largest", "\u00D7", "1.4"),
                  "change1.6" = paste("Largest", "\u00D7", "1.6"),
                  "const0.05" = paste("All", "\u00b1", "0.05"),
                  "const0.1" = paste("All", "\u00b1", "0.10"),
                  "const0.15" = paste("All", "\u00b1", "0.15"),
                  "permute" = "Permute",
                  "truegraph" = "Same DGP"
)

graph_names <- c("Empirical\nSparse" = "graph3",
                 "Simulated\nChain" = "graph4",
                 "Simulated\nNonsparse" = "graph5")

norm_names <- c("frob" = "Frobenius",
                "l1" = "\u2113[1]",
                "maxdiff" = "Maxdiff")

tp_levels <- c("50" = "1", "100" = "2", "200" = "3", "400" = "4", "1000" = "5")

# plotting linetypes
cond_lty <- set_names(c(1,2),
                      c("narrow", "wide"))



# Restructure results for proper plotting
df_comp_res <- df_comp_res %>% 
  mutate(comp = as.factor(comp)) %>% 
  mutate(prior = as.factor(prior)) %>% 
  mutate(comp = forcats::fct_relevel(comp, "l1")) %>% 
  mutate(change = gsub("permute134256", "permute", change)) %>% 
  # delete prior from dgp column
  mutate(dgp = gsub("narrow_", "", dgp))

# Delete old conditions
df_comp_res <- df_comp_res %>% 
  dplyr::filter(!grepl("noise", change))

# write_rds(df_comp_res, here::here("output/df_comp_res.RDS"))

# Number of combinations
n_comp <- 100

# significance cutoff
sig_cut <- 0.05

# number of posterior draws
n_draw <- 2000

```

#### Posterior Diff > Empirical

Distribution of values under the null for the frobenius norm only.
TODO has to change
```{r}
plot_test_null_dist <- df_comp_res %>% 
          dplyr::filter(dgp %in% c("graph3", "graph4", "graph5")) %>% 
          dplyr::filter(change == "truegraph") %>% 
          dplyr::filter(comp == "frob") %>% 
          dplyr::filter(prior == "narrow") %>% 
          # mutate tp into factor
          mutate(tp = as.factor(tp)) %>% 
          mutate(tp = forcats::fct_relevel(tp, "50", "100", "200", "400", "1000")) %>% 
          mutate(dgp = case_match(dgp,
                                  "graph3" ~ "Empirical Sparse",
                                  "graph4" ~ "Simulated Chain",
                                  "graph5" ~ "Simulated Nonsparse")) %>% 
          pivot_longer(cols = c("beta", "pcor"), 
                       names_to = "res", values_to = "value") %>% 
          group_by(comp, tp, change, dgp, res) %>% 
          # compute pct larger than empirical 
          dplyr::summarize(pct_larger = value/n_draw) %>%  
          dplyr::mutate(res = case_match(res,
                                         "beta" ~ "Temporal",
                                         "pcor" ~ "Contemporaneous")) %>%
          ggplot(aes(x = pct_larger)) + 
          # geom_text(aes(label = round(pct_larger,1)), size = 4)+
          geom_histogram(bins = 100, fill = ggokabeito::palette_okabe_ito()[2])+
          ggh4x::facet_nested(tp ~ dgp + res,
                              scales = TRUE,
                              remove_labels = TRUE,
                              independent = "y")+
          theme_compare()+
          ggokabeito::scale_color_okabe_ito()+ 
          labs(x = "Test Value",
               y = "")+
          # scale_y_continuous(labels = NULL)+
          # add horizontal line between factors
          geom_vline(colour = "#F3F4F5", xintercept = seq(1.5, length(tp_levels), 1))+
          theme(
                  strip.text = ggplot2::element_text(face = "plain", size = ggplot2::rel(1.2),
                  hjust = 0.5),
                  strip.text.x.top = ggplot2::element_text(face = "plain", size = ggplot2::rel(1.2),
                  hjust = 0.5),
                  legend.text = ggplot2::element_text(face = "plain", size = ggplot2::rel(1.2)),
                  legend.title = ggplot2::element_text(face = "bold", size = ggplot2::rel(1.2)),
                  # panel.border = element_rect(color = "#D5D8DC", fill = NA, size = 1),
                  panel.spacing.y = ggplot2::unit(1.6, "lines"),
                  panel.spacing.x = ggplot2::unit(1.6, "lines"),
                  axis.line = element_line(colour = "#6d6d6e"),
                  axis.text.x = ggplot2::element_text(face = "plain", size = ggplot2::rel(0.95)),
                  axis.title.x = ggplot2::element_text(face = "plain", size = ggplot2::rel(1.3)),
                  axis.title.y = ggplot2::element_text(face = "plain", size = ggplot2::rel(1.3)),
                  panel.grid.major.x = element_blank())
          

plot_test_null_dist
ggsave(filename = "plot_test_null_dist_narrow_rev1.svg",plot_test_null_dist, device = "svg",
         path = here::here("figures/revision1/"), width = 14, height = 10)

  
```


### Decision Rule
What happens to power/false positives if we implement the following decision rule:
We combine the reference distribution, and look at the cutoff.


With uncertainty in the form of standard errors. 
```{r}
plot_dec_rule_se <- df_comp_res %>% 
          dplyr::filter(dgp %in% c("graph3", "graph4", "graph5")) %>% 
          dplyr::filter(change != "change1.2") %>% 
          dplyr::filter(change != "truegraph") %>% 
          # mutate tp_ind into factor
          dplyr::mutate(tp = as.factor(tp)) %>% 
          dplyr::mutate(tp = forcats::fct_relevel(tp, "50", "100", "200", "400", "1000")) %>% 
          dplyr::mutate(dgp = fct_recode(as_factor(as.character(dgp)), !!!graph_names)) %>% 
          dplyr::mutate(change = case_match(
            change,
                  "change1.2" ~ paste("Largest", "\u00D7", "1.2"),
                  "change1.4" ~ paste("Largest", "\u00D7", "1.4"),
                  "change1.6" ~ paste("Largest", "\u00D7", "1.6"),
                  "const0.05" ~ paste("All", "\u00b1", "0.05"),
                  "const0.1" ~ paste("All", "\u00b1", "0.10"),
                  "const0.15" ~ paste("All", "\u00b1", "0.15"),
                  "permute" ~ "Permute"
          )) %>% 
          dplyr::mutate(change = as.factor(change)) %>% 
          dplyr::mutate(change = forcats::fct_relevel(change, "Largest × 1.4", 
                                                      "Largest × 1.6",
                                                      "All ± 0.05",
                                                      "All ± 0.10",
                                                      "All ± 0.15")) %>% 
          # mutate(change = fct_recode(as_factor(as.character(change)), !!!change_names)) %>% 
          # setup decision rule
          dplyr::mutate(
                 sig_beta05 = ifelse(beta < sig_cut*n_draw, 
                                     1, 0),
                 sig_pcor05 = ifelse(pcor < sig_cut*n_draw, 
                                     1, 0)) %>% 
          # for now, only narrow prior
          dplyr::filter(prior == "narrow") %>%
          dplyr::group_by(dgp, comp, tp, change) %>% 
          dplyr::summarize(
                    power_beta05 = sum(sig_beta05)/n_comp,
                    power_pcor05 = sum(sig_pcor05)/n_comp,
                    se_beta05 = sqrt((power_beta05 * (1-power_beta05))/n_comp),
                    se_pcor05 = sqrt((power_pcor05 * (1-power_pcor05))/n_comp)) %>% 
          tidyr::pivot_longer(cols = c("power_beta05", "power_pcor05"), names_to = "res") %>%
          # attach correct se
          dplyr::mutate(se = ifelse(grepl("beta", res), se_beta05, se_pcor05)) %>% 
          dplyr::select(!c(se_beta05, se_pcor05)) %>% 
          dplyr::mutate(mat = case_when(
            grepl("beta05", res) ~ "Temporal",
            grepl("pcor05", res) ~ "Contemporaneous")) %>% 
          dplyr::ungroup() %>% 

          ## uncomment this to include both priors
          # ggplot(aes(x = tp, y = value, col = comp,
          #            group = interaction(comp, prior), linetype = prior)) +
          ggplot(aes(x = tp, y = value, col = comp,
                      group = comp)) +
          geom_errorbar(aes(ymin = value - 1*se,
                            ymax = value + 1*se),
                        width = .8, 
                 position = position_dodge(0.7),
                 show.legend = FALSE)+
          # geom_line()+
          geom_point(size = 1.2, position = position_dodge(0.7))+
          theme_compare()+
          # scale_linetype_manual(values = cond_lty)+
          ggh4x::facet_nested(change ~ dgp + mat,
                              axes = "all",
                              remove_labels = "all"
                              )+
          ggokabeito::scale_colour_okabe_ito()+
          labs(x = "Timepoints",
               y = "Power",
               col = "Norm",
               linetype = "Norm")+
          scale_y_continuous(limits = c(0,1), expand = c(0,0))+
          # add horizontal line between factors
          geom_vline(colour = "#F3F4F5", xintercept = seq(1.5, length(tp_levels), 1))+
            theme(
                  strip.text = ggplot2::element_text(face = "plain", size = ggplot2::rel(1.2),
                  hjust = 0.5),
                  strip.text.x.top = ggplot2::element_text(face = "plain", size = ggplot2::rel(1.2),
                  hjust = 0.5),
                  legend.text = ggplot2::element_text(face = "plain", size = ggplot2::rel(1.2)),
                  legend.title = ggplot2::element_text(face = "bold", size = ggplot2::rel(1.2)),
                  # panel.border = element_rect(color = "#D5D8DC", fill = NA, size = 1),
                  panel.spacing.y = ggplot2::unit(1.6, "lines"),
                  panel.spacing.x = ggplot2::unit(1.6, "lines"),
                  axis.line = element_line(colour = "#6d6d6e"),
                  axis.text.x = ggplot2::element_text(face = "plain", size = ggplot2::rel(0.95)),
                  axis.title.x = ggplot2::element_text(face = "plain", size = ggplot2::rel(1.3)),
                  axis.title.y = ggplot2::element_text(face = "plain", size = ggplot2::rel(1.3)),
                  panel.grid.major.x = element_blank())

plot_dec_rule_se
ggsave(filename = "plot_dec_rule_se_rev1.svg",plot_dec_rule_se, device = "svg", path = here::here("figures/revision1/"), width = 14, height = 12)

```




#### False Positives

With uncertainty:
```{r}
plot_false_positive_se <- df_comp_res %>%
          dplyr::filter(dgp %in% c("graph3", "graph4", "graph5")) %>%
          filter(change == "truegraph") %>%
          # setup decision rule
          mutate(sig_beta05 = ifelse(beta < sig_cut*n_draw, 1, 0),
                 sig_pcor05 = ifelse(pcor < sig_cut*n_draw , 1, 0)) %>%
          # mutate tp_ind into factor
          mutate(tp = as.factor(tp)) %>%
          mutate(tp = forcats::fct_relevel(tp, "50", "100", "200", "400", "1000")) %>%
          dplyr::mutate(dgp = fct_recode(as_factor(as.character(dgp)), !!!graph_names)) %>% 
        
          dplyr::group_by(dgp, comp, tp, change, prior) %>% 
          dplyr::summarize(
                    power_beta05 = sum(sig_beta05)/n_comp,
                    power_pcor05 = sum(sig_pcor05)/n_comp,
                    se_beta05 = sqrt((power_beta05 * (1-power_beta05))/n_comp),
                    se_pcor05 = sqrt((power_pcor05 * (1-power_pcor05))/n_comp)) %>% 
          tidyr::pivot_longer(cols = c("power_beta05", "power_pcor05"), names_to = "res") %>%
          # attach correct se
          dplyr::mutate(se = ifelse(grepl("beta", res), se_beta05, se_pcor05)) %>% 
          dplyr::select(!c(se_beta05, se_pcor05)) %>% 
          dplyr::mutate(mat = case_when(
            grepl("beta05", res) ~ "Temporal",
            grepl("pcor05", res) ~ "Contemp.")) %>% 
          dplyr::filter(prior == "narrow") %>% 
          ggplot(aes(x = tp, y = value, 
                     col = comp, group = comp)) +
          geom_errorbar(aes(ymin = value - 1*se,
                            ymax = value + 1*se),
                        width = .8, 
                 position = position_dodge(0.7),
                 show.legend = FALSE)+
          # geom_line()+
          geom_point(size = 1.2, position = position_dodge(0.7))+
          ggh4x::facet_nested(. ~ dgp + mat,
                              axes = TRUE,
                              remove_labels = TRUE)+
          # scale_y_continuous(expand = c(0,0))+
          coord_cartesian(ylim = c(0, .15),
                          expand = FALSE,
                          xlim = c(0.5, 5.5))+
          # ylim(-0.1,.2)+
          ggokabeito::scale_color_okabe_ito()+
          theme_compare()+
          geom_hline(yintercept = 0.05, col = "#D5D8DC")+ 
          labs(x = "Timepoints", 
               col = "Norm",
               linetype = "Norm",
               y = "Proportion of false positives")+
          # add horizontal line between factors
          geom_vline(colour = "#F3F4F5", xintercept = seq(1.5, length(tp_levels), 1))+
          theme(
                  strip.text = ggplot2::element_text(face = "plain", size = ggplot2::rel(1.2),
                  hjust = 0.5),
                  strip.text.x.top = ggplot2::element_text(face = "plain", size = ggplot2::rel(1.2),
                  hjust = 0.5),
                  legend.text = ggplot2::element_text(face = "plain", size = ggplot2::rel(1.2)),
                  legend.title = ggplot2::element_text(face = "bold", size = ggplot2::rel(1.2)),
                  # panel.border = element_rect(color = "#D5D8DC", fill = NA, size = 1),
                  panel.spacing.y = ggplot2::unit(1.6, "lines"),
                  panel.spacing.x = ggplot2::unit(1.6, "lines"),
                  axis.line = element_line(colour = "#6d6d6e"),
                  axis.text.x = ggplot2::element_text(face = "plain", size = ggplot2::rel(0.95)),
                  axis.title.x = ggplot2::element_text(face = "plain", size = ggplot2::rel(1.3)),
                  axis.title.y = ggplot2::element_text(face = "plain", size = ggplot2::rel(1.3)),
                  panel.grid.major.x = element_blank())

plot_false_positive_se
ggsave(filename = paste0("plot_false_positive_se_rev1.svg"),plot_false_positive_se, device = "svg",
         path = here::here("figures/revision1/"), width = 13, height = 6)
```



### Prior sensitivity graph
To keep everything clearer visually, we only use one norm (Frobenius) for now. 
```{r}
plot_dec_rule_prior_sens <- df_comp_res %>% 
          dplyr::filter(comp == "frob") %>% 
          dplyr::filter(dgp %in% c("graph3", "graph4", "graph5",
                                   "narrow_graph3", "narrow_graph4", "narrow_graph5")) %>% 
          dplyr::filter(change != "change1.2") %>% 
          dplyr::filter(change != "truegraph") %>% 
          mutate(dgp = case_match(dgp,
                                  "narrow_graph3" ~ "graph3",
                                  "narrow_graph4" ~ "graph4",
                                  "narrow_graph5" ~ "graph5",
                                  .default = dgp)) %>% 
          # mutate tp_ind into factor
          mutate(tp = as.factor(tp)) %>% 
          mutate(tp = forcats::fct_relevel(tp, "50", "100", "200", "400", "1000")) %>% 
          # separate graph and prior
          # tidyr::separate_wider_delim(cols = dgp, delim = "_", names = c("prior", "dgp")) %>% 
          mutate(dgp = case_match(dgp,
                                  "graph3" ~ "Empirical Sparse",
                                  "graph4" ~ "Simulated Chain",
                                  "graph5" ~ "Simulated Nonsparse")) %>%
         dplyr::mutate(change = case_match(
            change,
                  "change1.2" ~ paste("Largest", "\u00D7", "1.2"),
                  "change1.4" ~ paste("Largest", "\u00D7", "1.4"),
                  "change1.6" ~ paste("Largest", "\u00D7", "1.6"),
                  "const0.05" ~ paste("All", "\u00b1", "0.05"),
                  "const0.1" ~ paste("All", "\u00b1", "0.10"),
                  "const0.15" ~ paste("All", "\u00b1", "0.15"),
                  "permute" ~ "Permute"
          )) %>% 
          dplyr::mutate(change = as.factor(change)) %>% 
          dplyr::mutate(change = forcats::fct_relevel(change, "Largest × 1.4", 
                                                      "Largest × 1.6",
                                                      "All ± 0.05",
                                                      "All ± 0.10",
                                                      "All ± 0.15")) %>% 
          # setup decision rule
          mutate(sig_beta05 = ifelse(beta < sig_cut*n_draw, 1, 0),
                 sig_pcor05 = ifelse(pcor < sig_cut*n_draw , 1, 0)) %>%
          dplyr::group_by(dgp, comp, prior, tp, change) %>% 
          dplyr::summarize(
                    power_beta05 = sum(sig_beta05)/n_comp,
                    power_pcor05 = sum(sig_pcor05)/n_comp,
                    se_beta05 = sqrt((power_beta05 * (1-power_beta05))/n_comp),
                    se_pcor05 = sqrt((power_pcor05 * (1-power_pcor05))/n_comp)) %>% 
          tidyr::pivot_longer(cols = c("power_beta05", "power_pcor05"), names_to = "res") %>%
          # attach correct se
          dplyr::mutate(se = ifelse(grepl("beta", res), se_beta05, se_pcor05)) %>% 
          dplyr::select(!c(se_beta05, se_pcor05)) %>% 
          dplyr::mutate(mat = case_when(
            grepl("beta05", res) ~ "Temporal",
            grepl("pcor05", res) ~ "Contemp.")) %>%  
          
          ggplot(aes(x = tp, y = value, color = prior, group = prior)) + 
          ggh4x::facet_nested(change ~ dgp + mat,
                              axes = TRUE,
                              remove_labels = TRUE)+
          geom_errorbar(aes(ymin = value - 1*se,
                            ymax = value + 1*se),
                        width = .8, 
                        position = position_dodge(0.7),
                 show.legend = FALSE)+
          # geom_line()+
          geom_point(size = 1.2, position = position_dodge(0.7))+
          ggokabeito::scale_colour_okabe_ito()+
          theme_compare()+
          labs(x = "Timepoints",
               y = "Power",
               col = "Prior")+
          # add horizontal line between factors
          geom_vline(colour = "#F3F4F5", xintercept = seq(1.5, length(tp_levels), 1))+
          theme(
                  strip.text = ggplot2::element_text(face = "plain", size = ggplot2::rel(1.2),
                  hjust = 0.5),
                  strip.text.x.top = ggplot2::element_text(face = "plain", size = ggplot2::rel(1.2),
                  hjust = 0.5),
                  legend.text = ggplot2::element_text(face = "plain", size = ggplot2::rel(1.2)),
                  legend.title = ggplot2::element_text(face = "bold", size = ggplot2::rel(1.2)),
                  # panel.border = element_rect(color = "#D5D8DC", fill = NA, size = 1),
                  panel.spacing.y = ggplot2::unit(1.6, "lines"),
                  panel.spacing.x = ggplot2::unit(1.6, "lines"),
                  axis.line = element_line(colour = "#6d6d6e"),
                  axis.text.x = ggplot2::element_text(face = "plain", size = ggplot2::rel(0.95)),
                  axis.title.x = ggplot2::element_text(face = "plain", size = ggplot2::rel(1.3)),
                  axis.title.y = ggplot2::element_text(face = "plain", size = ggplot2::rel(1.3)),
                  panel.grid.major.x = element_blank())


plot_dec_rule_prior_sens
ggsave(filename ="plot_dec_rule_prior_sens_rev1.svg",plot_dec_rule_prior_sens, device = "svg",
         path = here::here("figures/revision1/"), width = 13, height = 10)
```


Now do the same for false positives:
```{r}
plot_false_positive_se_prior_sens <- df_comp_res %>%
          dplyr::filter(comp == "frob") %>% 
          dplyr::filter(dgp %in% c("graph3", "graph4", "graph5")) %>%
          dplyr::filter(change == "truegraph") %>%
          # setup decision rule
          mutate(sig_beta05 = ifelse(beta < sig_cut*n_draw, 1, 0),
                 sig_pcor05 = ifelse(pcor < sig_cut*n_draw , 1, 0)) %>%
          # mutate tp_ind into factor
          dplyr::mutate(tp = as.factor(tp)) %>%
          dplyr::mutate(tp = forcats::fct_relevel(tp, "50", "100", "200", "400", "1000")) %>%
          dplyr::mutate(dgp = fct_recode(as_factor(as.character(dgp)), !!!graph_names)) %>% 
          dplyr::group_by(dgp, comp, tp, change, prior) %>% 
          dplyr::summarize(
                    power_beta05 = sum(sig_beta05)/n_comp,
                    power_pcor05 = sum(sig_pcor05)/n_comp,
                    se_beta05 = sqrt((power_beta05 * (1-power_beta05))/n_comp),
                    se_pcor05 = sqrt((power_pcor05 * (1-power_pcor05))/n_comp)) %>% 
          dplyr::mutate(change = case_match(
            change,
                  "change1.2" ~ paste("Largest", "\u00D7", "1.2"),
                  "change1.4" ~ paste("Largest", "\u00D7", "1.4"),
                  "change1.6" ~ paste("Largest", "\u00D7", "1.6"),
                  "const0.05" ~ paste("All", "\u00b1", "0.05"),
                  "const0.1" ~ paste("All", "\u00b1", "0.10"),
                  "const0.15" ~ paste("All", "\u00b1", "0.15"),
                  "permute" ~ "Permute"
          )) %>% 
          tidyr::pivot_longer(cols = c("power_beta05", "power_pcor05"), names_to = "res") %>%
          # attach correct se
          dplyr::mutate(se = ifelse(grepl("beta", res), se_beta05, se_pcor05)) %>% 
          dplyr::select(!c(se_beta05, se_pcor05)) %>% 
          dplyr::mutate(mat = case_when(
            grepl("beta05", res) ~ "Temporal",
            grepl("pcor05", res) ~ "Contemp.")) %>% 
          # dplyr::filter(prior == "narrow") %>% 
          ggplot(aes(x = tp, y = value, color = prior, group = prior)) +
          geom_errorbar(aes(ymin = value - 1*se,
                            ymax = value + 1*se),
                        width = .8, 
                        position = position_dodge(0.7),
                 show.legend = FALSE)+
          # geom_line()+
          geom_point(size = 1.2, position = position_dodge(0.7))+
          ggh4x::facet_nested(. ~ dgp + mat,
                              axes = TRUE,
                              remove_labels = TRUE)+
          coord_cartesian(ylim = c(0, .2), 
                          expand = FALSE,
                          xlim = c(0.5, 5.5))+
          ggokabeito::scale_color_okabe_ito()+
          theme_compare()+
          geom_hline(yintercept = 0.05, col = "#D5D8DC")+ 
          labs(x = "Timepoints", 
               col = "Prior",
               y = "Proportion of false positives")+
          # add horizontal line between factors
          geom_vline(colour = "#F3F4F5", xintercept = seq(1.5, length(tp_levels), 1))+
              theme(
                  strip.text = ggplot2::element_text(face = "plain", size = ggplot2::rel(1.2),
                  hjust = 0.5),
                  strip.text.x.top = ggplot2::element_text(face = "plain", size = ggplot2::rel(1.2),
                  hjust = 0.5),
                  legend.text = ggplot2::element_text(face = "plain", size = ggplot2::rel(1.2)),
                  legend.title = ggplot2::element_text(face = "bold", size = ggplot2::rel(1.2)),
                  # panel.border = element_rect(color = "#D5D8DC", fill = NA, size = 1),
                  panel.spacing.y = ggplot2::unit(1.6, "lines"),
                  panel.spacing.x = ggplot2::unit(1.6, "lines"),
                  axis.line = element_line(colour = "#6d6d6e"),
                  axis.text.x = ggplot2::element_text(face = "plain", size = ggplot2::rel(0.95)),
                  axis.title.x = ggplot2::element_text(face = "plain", size = ggplot2::rel(1.3)),
                  axis.title.y = ggplot2::element_text(face = "plain", size = ggplot2::rel(1.3)),
                  panel.grid.major.x = element_blank())

plot_false_positive_se_prior_sens
ggsave(filename = paste0("plot_false_positive_se_prior_sens_rev1.svg"),plot_false_positive_se_prior_sens, device = "svg",
         path = here::here("figures/revision1/"), width = 13, height = 6)


```


### Norms across conditions
How large are the norms across the simulation conditions?
This is not included in the manuscript, was just an exploration.
```{r}
v_graphs <- c("graph1", "graph2", "graph3", "graph4", "graph5", "graph6")

for(g in v_graphs){
  
  p <- df_comp_res %>% 
        filter(dgp == g) %>% 
        mutate(comp = as.factor(comp),
               tp = as.numeric(tp),
               change = as.factor(change),
               emp  = as.numeric(emp)) %>% 
        group_by(comp, dgp, change, tp) %>% 
        summarize(mean_emp = mean(emp),
                  sd_emp = sd(emp)) %>%
        ggplot(aes(x = as.numeric(tp), y = mean_emp, col = comp))+
        geom_line()+
        geom_ribbon(aes(ymin = mean_emp - sd_emp, ymax = mean_emp + sd_emp, fill = comp), 
                    alpha = 0.4, colour = NA)+
        ggh4x::facet_grid2(change ~ comp, scales = "free", independent = "y")+
        theme_minimal()+
        scale_color_okabe_ito()+
        scale_fill_okabe_ito()+
        labs(caption = g,
             x = "Timepoints",
             y = "Mean Distance")

  
  ggsave(filename = paste0("plot_emp_norms_", g, ".svg"),p, device = "svg",
         path = here("figures/"))
  print(p)
}
```






