---
title: "posterior-simulation-var"
author: "Bj√∂rn Siepe"
date: "`r Sys.Date()`"
output: html_document
---

This document contains the posterior simulation method. 

# Simulating from posterior approach
Use random samples from the posterior to simulate new datasets. This is not our current approach anymore. 
```{r sim-from-posterior}
before_simpost <- Sys.time()
# Setup parallel
ncores = parallel::detectCores() - 2
cl = makeCluster(ncores)
registerDoParallel(cl)
# Create storage
l_data <- list()
l_data$graph3 <- l_data$graph2 <- l_data$graph1 <- list()
# Loop over timepoint conditions
for(t in seq_along(n_tp)){
  l_data$graph1[[t]] <- lapply(l_res$graph1[[t]], function(x){sim_from_post_parallel(
    fitobj = x, n = n_ind, n_datasets = n_postds, tp = n_tp,
    iterations = n_iter, means = 0, seed = seed, convert_bggm = FALSE)})
  
  l_data$graph2[[t]] <- lapply(l_res$graph2[[t]], function(x){sim_from_post_parallel(
    fitobj = x, n = n_ind, n_datasets = n_postds, tp = n_tp,
    iterations = n_iter, means = 0, seed = seed, convert_bggm = FALSE)})

  l_data$graph3[[t]] <- lapply(l_res$graph3[[t]], function(x){sim_from_post_parallel(
    fitobj = x, n = n_ind, n_datasets = n_postds, tp = n_tp,
    iterations = n_iter, means = 0, seed = seed, convert_bggm = FALSE)})
}

stopCluster(cl)
after_simpost <- Sys.time()

write_rds(l_data, "l_data_new.Rds")
# l_data <- readRDS(here("l_data.Rds"))


```

Double check simulation for correct transposing of weights matrix
```{r}
sim_check <- graphicalVARsim(3000, beta = t(l_res$graph1[[4]]$truegraph[[1]]$beta_mu), kappa = l_res$graph1[[4]]$truegraph[[1]]$kappa_mu)
sim_check <- as.data.frame(sim_check)
sim_check_res <- var_estimate(sim_check)

sim_check_res$beta_mu-l_res$graph1[[4]]$truegraph[[1]]$beta_mu

```




## Refit on posterior predictive data
Compute different norms between models on resampled datasets compared to reference model and then compare to actual difference between two models. 
```{r}
before_par_fit <- Sys.time()
ncores = parallel::detectCores() - 3
cl = makeCluster(ncores)
registerDoParallel(cl)
l_postres <- list()
l_postres$graph3 <- l_postres$graph2 <- l_postres$graph1 <- list()
for(t in seq_along(n_tp)){
  l_postres$graph1[[t]] <- lapply(l_data$graph1[[t]], function(x){fit_var_parallel_post(
                 data = x, n = n_ind, nds = n_postds,
                 rho_prior = rho_sd, beta_prior = beta_sd, seed = seed,
                 iterations = n_iter, posteriorsamples = TRUE, pruneresults = TRUE)}) 
  
  l_postres$graph2[[t]] <- lapply(l_data$graph2[[t]], function(x){fit_var_parallel_post(
                 data = x, n = n_ind, nds = n_postds,
                 rho_prior = rho_sd, beta_prior = beta_sd, seed = seed,
                 iterations = n_iter, posteriorsamples = TRUE, pruneresults = TRUE)})

  l_postres$graph3[[t]] <- lapply(l_data$graph3[[t]], function(x){fit_var_parallel_post(
                 data = x, n = n_ind, nds = n_postds,
                 rho_prior = rho_sd, beta_prior = beta_sd, seed = seed,
                 iterations = n_iter, posteriorsamples = TRUE, pruneresults = TRUE)})


}


stopCluster(cl)
after_par_fit <- Sys.time() - before_par_fit    # around 1h per graph (with 15 individuals)

write_rds(l_postres, "l_postres_new.Rds")
# l_postres <- readRDS(here("l_postres.Rds"))



```


## Evaluation of posterior refitting approach

Then, start the evaluation. 
Maxdiff still throws an error here, which is indicative of non-convergence

```{r eval-posterior-refit}
# All possible model combinations
comp_combinations <- expand_grid_unique(mod_a = seq(1, n_ind, 1),
                                 mod_b = seq(1, n_ind, 1))
# number of data-generating processes
n_dgp <- 1
# Number of comparison types
n_c_types <- 3

# Number of different changed graph structures
n_g_types <- 7

# Number of different tp conditions
n_t_types <- 4


dgp_names <- c("graph1", "graph2", "graph3")
change_names <- c("truegraph", "change1.4", "change1.6",
                  "noise0.1", "noise0.2", "noise0.3", "perm")
comp_names <- c("frob","maxdiff", "l1")


# Number of comparison combinations
n_c_comb <- nrow(comp_combinations)


# Setup storage
l_comp<- list()

# Loop over data-generating processes
for(d in seq(n_dgp)){
  l_comp[[d]] <- list()
  # Loop over timepoint conditions
  for(t in seq(n_t_types)){
    l_comp[[d]][[t]] <- list() 
    # Loop over changed graphs
    for(c in seq(n_g_types)){
      l_comp[[d]][[t]][[c]] <- list()
      # Loop over model combinations
      for(m in seq(n_c_comb)){
        l_comp[[d]][[t]][[c]][[m]] <- list()
        # Loop over comparison types
        for(c_type in seq(n_c_types)){
          l_comp[[d]][[t]][[c]][[m]][[c_type]] <- list()
          l_comp[[d]][[t]][[c]][[m]][[c_type]] <- cross_compare(
                      postpost = FALSE,
                      mod_a = comp_combinations[m, 1],
                      mod_b = comp_combinations[m, 2],
                      # [[1]] indexes the truegraph
                      fitpost_a = l_postres[[d]][[t]][[1]],
                      fitpost_b = l_postres[[d]][[t]][[c]],
                      fitemp_a = l_res[[d]][[t]][[1]],
                      fitemp_b = l_res[[d]][[t]][[c]],
                      n_datasets = 100,
                      comparison = comp_names[c_type])
          # Store relevant parameters for evaluation
         l_comp[[d]][[t]][[c]][[m]][[c_type]]$params <- data.frame(
           dgp = dgp_names[d],
           tp = n_tp[t],
           comp_graph = change_names[c]
         )
        } 

        
        
      }
    }
  }
}



```


Evaluation: 
- number of posterior sample distances > empirical distance
```{r eval-comp}
l_eval <- list()
# Loop over data-generating processes
for(d in seq(n_dgp)){
  l_eval[[d]] <- list()
  # Loop over timepoint conditions
  for(t in seq(n_t_types)){
    l_eval[[d]][[t]] <- list() 
    # Loop over changed graphs
    for(c in seq(n_g_types)){
      l_eval[[d]][[t]][[c]] <- list()
      # Loop over model combinations
      for(m in seq(n_c_comb)){
        l_eval[[d]][[t]][[c]][[m]] <- list()
        l_eval[[d]][[t]][[c]][[m]] <- lapply(l_comp[[d]][[t]][[c]][[m]],cross_compare_eval)

      }
    }
  }
}


# Now unpack
df_eval <- rrapply::rrapply(l_eval, how = "bind")




```


Now we can plot the results. First, power to detect true differences:
```{r}
eval_plot_diffgraph <- df_eval %>% 
  pivot_longer(cols = c("beta_a", "beta_b", "pcor_a", "pcor_b"), names_to = "res") %>% 
  # mutate(across(c(comp, dgp, tp, comp_graph, res),
                # ~ as.factor(.))) %>% 
  filter(dgp == "graph1") %>% 
  # comp_graph == truegraph is comparison with same dgp, so null
  filter(comp_graph != "truegraph") %>% 
  mutate(sig05 = ifelse(value <= 5, 1, 0),
         sig01 = ifelse(value <= 1, 1, 0)) %>%
  group_by(comp, tp, comp_graph, res) %>%
  mutate(n_comp = n()) %>%  
  summarize(power05 = sum(sig05)/n_comp) %>% 
  # somehow does not cut everything if I don't do this
  summarize(power05 = mean(power05)) %>% 
  ggplot(aes(x = tp, y = power05, col = comp)) + 
  geom_line()+
  facet_grid(comp_graph ~ res)+
  theme_minimal()+
  scale_color_okabe_ito()+
  labs(title = "Graph Fried (2020) as Comparison",
       caption = "Rho_SD = 0.3, Beta_sd = 1")
ggsave("eval_plot_diffgraph.svg", device = "svg", path = here("figures/"))  


```







## Compare with full posterior differences
Instead of only taking the empirical difference between fits, we generate a distribution of posterior differences _between_ models.  

```{r posterior-differences-between}
post_diff <- cross_compare_post(comparison = "l1")
post_diff %>% 
  bind_rows(., .id = "matrix") %>% 
  pivot_longer(cols = c("null", "emp"), names_to = "dist") %>% 
  ggplot(aes(x = value, group = dist, color = dist, fill = dist))+
  geom_density()+
  theme_minimal()
```


## Compare with bootstrapped posterior models
We now generate a distribution of posterior differences _within_ models. 
```{r posterior differences-within}
wc_res <- within_compare(
                      mod_a = 1,
                      mod_b = 2,
                      # [[1]] indexes the truegraph
                      fitpost_a = l_postres[[1]][[3]][[1]],
                      fitpost_b = l_postres[[1]][[3]][[2]],
                      fitemp_a = l_res[[1]][[3]][[1]],
                      fitemp_b = l_res[[1]][[3]][[2]],
                      n_datasets = 100,
                      comparison = "frob",
                      n_draws = 1000)


wc_res %>% 
  filter(mat == "beta") %>% 
  # pivot_longer(cols = c("null", "emp"), names_to = "res") %>% 
  ggplot(aes(x = null))+
  geom_density()+
  geom_vline(aes(xintercept = emp))


```

Do this for all models.
```{r}
# All possible model combinations
comp_combinations <- expand_grid_unique(mod_a = seq(1, n_ind, 1),
                                 mod_b = seq(1, n_ind, 1))
# number of data-generating processes
n_dgp <- 3
# Number of comparison types
n_c_types <- 3

# Number of different changed graph structures
n_g_types <- 7

# Number of different tp conditions
n_t_types <- 4

dgp_names <- c("graph1", "graph2", "graph3")

change_names <- c("truegraph", "change1.2", "change1.4", "change1.6",
                  "noise0.1", "noise0.2", "noise0.3", "perm")


comp_names <- c("frob","maxdiff", "l1")

# Number of comparison combinations
n_c_comb <- nrow(comp_combinations)

# Setup storage
l_comp_within<- list()

# Loop over data-generating processes
for(d in seq(n_dgp)){
  l_comp_within[[d]] <- list()
  # Loop over timepoint conditions
  for(t in seq(n_t_types)){
    l_comp_within[[d]][[t]] <- list() 
    # Loop over changed graphs
    for(c in seq(n_g_types)){
      l_comp_within[[d]][[t]][[c]] <- list()
      # Loop over model combinations
      for(m in seq(n_c_comb)){
        l_comp_within[[d]][[t]][[c]][[m]] <- list()
        # Loop over comparison types
        for(c_type in seq(n_c_types)){
          l_comp_within[[d]][[t]][[c]][[m]][[c_type]] <- list()
          l_comp_within[[d]][[t]][[c]][[m]][[c_type]]$res <- within_compare(
                      mod_a = comp_combinations[m, 1],
                      mod_b = comp_combinations[m, 2],
                      # [[1]] indexes the truegraph
                      fitpost_a = l_postres[[d]][[t]][[1]],
                      fitpost_b = l_postres[[d]][[t]][[c]],
                      fitemp_a = l_res[[d]][[t]][[1]],
                      fitemp_b = l_res[[d]][[t]][[c]],
                      n_datasets = 100,
                      n_draws = 1000,
                      comparison = comp_names[c_type])
         # Store relevant parameters for evaluation
         l_comp_within[[d]][[t]][[c]][[m]][[c_type]]$params <- list(
           dgp = dgp_names[d],
           tp = n_tp[t],
           comp_graph = change_names[c]
         )
        } 

        
        
      }
    }
  }
}


```

Now evaluate this: 
```{r}
within_compare_eval(l_res = l_comp_within[[1]][[3]][[4]][[1]][[1]])


# Set up for all simulation conditions
l_eval_within <- list()
# Loop over data-generating processes
# TODO change back to seg(n_dgp)
for(d in seq(n_dgp)){
  l_eval_within[[d]] <- list()
  # Loop over timepoint conditions
  for(t in seq(n_t_types)){
    l_eval_within[[d]][[t]] <- list() 
    # Loop over changed graphs
    for(c in seq(n_g_types)){
      l_eval_within[[d]][[t]][[c]] <- list()
      # Loop over model combinations
      for(m in seq(n_c_comb)){
        l_eval_within[[d]][[t]][[c]][[m]] <- list()
        l_eval_within[[d]][[t]][[c]][[m]] <- lapply(l_comp_within[[d]][[t]][[c]][[m]],within_compare_eval)

      }
    }
  }
}


# Now unpack
df_eval_within <- rrapply::rrapply(l_eval_within, how = "bind")


```


Plot
```{r}
df_eval_within %>% 
  pivot_longer(cols = c("beta_a", "beta_b", "pcor_a", "pcor_b"), names_to = "res") %>% 
  # mutate(across(c(comp, dgp, tp, comp_graph, res),
                # ~ as.factor(.))) %>% 
  filter(dgp == "graph1") %>% 
  # comp_graph == truegraph is comparison with same dgp, so null
  filter(comp_graph != "truegraph") %>% 
  mutate(sig05 = ifelse(value < 50, 1, 0),
         sig01 = ifelse(value < 10, 1, 0)) %>%
  group_by(comp, tp, comp_graph, res) %>%
  mutate(n_comp = n()) %>%  
  summarize(power05 = sum(sig05)/n_comp) %>% 
  # somehow does not cut everything if I don't do this
  summarize(power05 = mean(power05)) %>% 
  ggplot(aes(x = tp, y = power05, col = comp)) + 
  geom_line()+
  facet_grid(comp_graph ~ res)+
  theme_minimal()+
  scale_color_okabe_ito()



```

