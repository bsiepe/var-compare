---
title: "var-compare-empirical-example"
author: "Bj√∂rn Siepe"
date: "2023-01-30"
output: html_document
---

We use data from Fisher et al. (2017), downloaded from https://github.com/jmbh/EmotionTimeSeries/blob/master/DataClean/Fisher2017/data_Fisher2017.RDS. 

# Preparation and Data Cleaning
```{r}
library(BGGM)
library(qgraph)
library(tidyverse)
library(foreach)
library(doParallel)

data <- readRDS("data_Fisher2017.RDS")


# Number of observations per model
n_obs <- data %>% 
  count(subj_id)

# Use 6 items
short_data <- data %>% 
  # dplyr::filter(subj_id %in% rel_ids) %>% 
  dplyr::select(subj_id, content, worried, anhedonia, positive, fatigue, accepted) %>% 
  group_by(subj_id) %>% 
  mutate(tp = row_number()) %>% 
  ungroup() %>% 
  split(.$subj_id)


short_data <- data %>% 
  # dplyr::filter(subj_id %in% rel_ids) %>% 
  dplyr::select(subj_id, reassure, down, anhedonia, enthusiastic, hopeless, accepted) %>% 
  group_by(subj_id) %>% 
  mutate(tp = row_number()) %>% 
  ungroup() %>% 
  split(.$subj_id)



```


## Detrending

TODO: Double check if this worked
```{r}
# Relevant variables
rel_vars <- c("content", "worried", "anhedonia", "positive", "fatigue", "accepted")
rel_vars <- c("reassure", "down", "anhedonia", "enthusiastic", "hopeless", "accepted")

data_detrend <- lapply(short_data, function(x){
  for (v in 1:length(rel_vars)){
  # Respektive Variable auf die Zeit regressieren
  lm_form <- as.formula(paste0(rel_vars[v], "~ tp"))
  # lineares Modell rechnen
  lm_res <- summary(lm(lm_form, data = x))
  # wenn der Zeittrend signifikant ist, detrenden wir mit den Residuen
  # [,4] greift auf die Spalte der p-Werte zu
  # [2] auf den p-Wert des Regressionsgewichts des Datums
  if(lm_res$coefficients[,4][2] < 0.05){
    print(paste0("Detrende Variable: ", rel_vars[v]))
    x[!is.na(x[rel_vars[v]]),rel_vars[v]] <- residuals(lm_res)
  }
  
}
return(x)
})





```



# Fitting
Fit all models
```{r}
rho_prior = 0.25
beta_prior = .5
iterations = 50000
seed = 2022

df_prior <- data.frame(
  rho_prior = c(0.1, 0.25, 0.5),
  beta_prior = c(0.25, 0.5, 1)
)


l_fits <- list()

cl = makeCluster(3)
registerDoParallel(cl)
l_fits <- foreach(i = 1:nrow(df_prior), .packages = "BGGM") %dopar% {
  fit <- lapply(data_detrend, function(x){
  tryCatch(BGGM::var_estimate(x[,-c(1, 8)],      # delete id column and tp column for fitting
                     rho_sd = df_prior[i,"rho_prior"],
                     beta_sd = df_prior[i, "beta_prior"],
                     iter = iterations, 
                     seed = seed), error = function(e) NA)
  
})
  return(fit)
}

stopCluster(cl)  
  
  

# Fitting with one prior 
l_fits <- lapply(data_detrend, function(x){
  tryCatch(BGGM::var_estimate(x[,-c(1, 8)],      # delete id column and tp column for fitting
                     rho_sd = rho_prior,
                     beta_sd = beta_prior,
                     iter = iterations, 
                     seed = seed), error = function(e) NA)
})

# delete nonconverged
# l_fits <- l_fits[sapply(l_fits, is.list)]
# get param names
param_names <- BGGM::convergence(l_fits[[1]], print_names = TRUE)




```


## Convergence 

```{r}
# Trace Plots
BGGM::convergence(l_fits[[1]], type = "trace",  param = "reassure--accepted")

# ACF
BGGM::convergence(l_fits[[1]], type = "acf", param = "down--enthusiastic")


# pdf("convergence_empirical.pdf")
# for(i in 1:10){
#   for(n in param_names){
# 
#   print(BGGM::convergence(l_fits[[1]], type = "acf", param = n))
#   
# }
# }
# dev.off()

# Try to calculate effective sample size
bet <- l_fits[[1]]$fit$beta[,,51:iterations+50]

# Convert to matrix where each col is a variable
m_bet <- t(matrix(bet, 6*6, iterations))
mcmc_bet <- as.mcmc(m_bet)
coda::effectiveSize(mcmc_bet)

# Same for pcor
pcor <- l_fits[[1]]$fit$pcors[,,51:iterations+50]
m_pcor <- t(matrix(pcor, 6*6, iterations))
mcmc_pcor <- as.mcmc(m_pcor)
ces <- coda::effectiveSize(mcmc_pcor)


# Get ESS for all samples
l_ess <- lapply(l_fits, var_ess)

```


## Plot all networks

```{r}
plot_net <- function(fit_obj){
  par(mfrow=c(1,2))
  qgraph::qgraph(fit_obj$beta_mu, title = "Temporal", theme = "colorblind", layout = "circle")
  qgraph::qgraph(fit_obj$pcor_mu, title = "Contemporaneous", theme = "colorblind", layout = "circle")
}


```






Temporary new function for post distance within without kappa and compare_var

TODO write summary method for compare function
```{r}

compare_var <- function(fit_a, 
                        fit_b, 
                        cutoff = 5,           # percentage level of test
                        dec_rule = "OR",
                        n_draws = 1000,
                        comp = "frob"){
  
  ## Create reference distributions for both models
  ref_a <- post_distance_within(fit_a, comp = comp, pred = FALSE, draws = n_draws)
  ref_b <- post_distance_within(fit_b, comp = comp, pred = FALSE, draws = n_draws)
  
  ## Empirical distance
    # Compute empirical distance as test statistic
    if(comp == "frob"){
      normtype = "F"
      # Compute Distance of empirical betas between a and b
      emp_beta <- tryCatch(norm(fit_a$beta_mu - fit_b$beta_mu, type = normtype), error = function(e) {NA})
      
      # Compute Distance of empirical pcors between a and b
      emp_pcor <- tryCatch(norm(fit_a$pcor_mu - fit_b$pcor_mu, type = normtype), error = function(e) {NA})
      
    }
    
    if(comp == "maxdiff"){
      # Compute maxdiff of empirical betas between a and b
      emp_beta <- tryCatch(max(abs(fit_a$beta_mu - fit_b$beta_mu)), error = function(e) {NA})
      
      # Compute maxdiff of empirical pcors between a and b
      emp_pcor <- tryCatch(max(abs(fit_a$pcor_mu - fit_b$pcor_mu)), error = function(e) {NA})

    }
    
    if(comp == "l1"){
      # Compute l1 of empirical betas between a and b
      emp_beta <- tryCatch(sum(abs(fit_a$beta_mu - fit_b$beta_mu)), error = function(e) {NA})
      
      # Compute l1 of empirical pcors between a and b
      emp_pcor <- tryCatch(sum(abs(fit_a$pcor_mu - fit_b$pcor_mu)), error = function(e) {NA})

    }
  ## Combine results
    res_beta <- data.frame(null = c(unlist(ref_a[["beta"]]), unlist(ref_b[["beta"]])),
                              mod = c(rep("mod_a", n_draws), rep("mod_b", n_draws)),
                              emp = rep(emp_beta, n_draws*2),
                              comp = rep(comp, n_draws*2))
    
    
    res_pcor <- data.frame(null = c(unlist(ref_a[["pcor"]]), unlist(ref_b[["pcor"]])),
                              mod = c(rep("mod_a", n_draws), rep("mod_b", n_draws)),
                              emp = rep(emp_pcor, n_draws*2),
                              comp = rep(comp, n_draws*2))
  
  ## Implement decision rule "OR"
  if(dec_rule == "OR"){
    suppressWarnings(sig_beta <- res_beta %>% 
      group_by(mod) %>% 
      summarize(sum_larger = sum(null > emp)) %>% 
      summarize(sig = ifelse(sum_larger < cutoff * (n_draws/100), 1, 0)) %>% 
      summarize(sig_decision = sum(sig)) %>% 
      pull(sig_decision))
    
    suppressWarnings(larger_beta <- res_beta %>% 
      group_by(mod) %>% 
      summarize(sum_larger = sum(null > emp))) %>% 
      pull(sum_larger)
    
    suppressWarnings(sig_pcor <- res_pcor %>% 
      group_by(mod) %>% 
      summarize(sum_larger = sum(null > emp)) %>% 
      summarize(sig = ifelse(sum_larger < cutoff * (n_draws/100), 1, 0)) %>% 
      summarize(sig_decision = sum(sig)) %>% 
      pull(sig_decision))
    
    suppressWarnings(larger_pcor<- res_pcor %>% 
      group_by(mod) %>% 
      summarize(sum_larger = sum(null > emp))) %>% 
      pull(sum_larger)
    
      
  }
  l_res <- list(sig_beta = sig_beta,
                sig_pcor = sig_pcor,
                res_beta = res_beta,
                res_pcor = res_pcor,
                emp_beta = emp_beta,
                emp_pcor = emp_pcor)

  return(l_res)
  

  
}

# Plotting method
# THIS IS ONLY TEMPORARY!!!!!
plot.compare_var <- function(compres,
                             ...){
  require(ggplot2)
  require(cowplot)
  # create df
  # dat <- rbind(compres$res_beta, compres$res_pcor)
  
  
  
  # Plotting
  plt_beta <- ggplot(compres$res_beta, 
                aes(x = null, fill = mod))+
    geom_density(alpha = .7)+
    theme_classic()+
    ggokabeito::scale_fill_okabe_ito()+
    geom_vline(aes(xintercept = compres$emp_beta), 
               col = "red", lty = 1, linewidth = .75)+
    labs(title = "Temporal")
  
  plt_pcor <- ggplot(compres$res_pcor, 
                aes(x = null, fill = mod))+
    geom_density(alpha = .7)+
    theme_classic()+
    ggokabeito::scale_fill_okabe_ito()+
    geom_vline(aes(xintercept = compres$emp_pcor), 
               col = "red", lty = 1, linewidth = .75)+
    labs(title = "Contemporaneous")
  
  leg <- get_legend(plt_beta)
  
  # Plot
  plt_tmp <- cowplot::plot_grid(plt_beta + theme(legend.position = "none"),
                            plt_pcor + theme(legend.position = "none"))

  # Add legend
  plt <- plot_grid(plt_tmp, leg, rel_widths = c(3, .4))
  plt
  
}





```






 
Test across all participants and across different priors. 
```{r}
fit_grid <- expand.grid(fit_a = as.numeric(names(l_fits[[1]])), 
                        fit_b = as.numeric(names(l_fits[[1]])), 
                        priors = seq(nrow(df_prior), 1), 
                        comp = c("l1", "frob", "maxdiff"))
l_comps <- list()
l_comps <- pbapply::pblapply(c(1:nrow(fit_grid)), function(x){
  
  a <- fit_grid$fit_a[x]
  b <- fit_grid$fit_b[x]
  
  if(is.list(l_fits[[a]]) & is.list(l_fits[[b]])){
    compare_var(l_fits[[a]],l_fits[[b]], comp = "l1")
  }
  
})

cl = makeCluster(14)
registerDoParallel(cl)
# Rewrite in parallel
l_comps <- foreach(i = 1:nrow(fit_grid), .export = c("compare_var", "post_distance_within")) %dopar% {
  
  # Extract information
  a <- fit_grid$fit_a[i]
  b <- fit_grid$fit_b[i]
  p_ind <- fit_grid$priors[i]
  comp <-  as.character(fit_grid$comp[i])
  

  
  # Compare
  if(is.list(l_fits[[p_ind]][[a]]) & is.list(l_fits[[p_ind]][[b]])){
  comp_res  <- compare_var(l_fits[[p_ind]][[a]],l_fits[[p_ind]][[b]], comp = comp)
  
  return(comp_res)
  }
  else
    return(NA)
  
  
    
  
  
}
stopCluster(cl)







# optional: delete full beta results
# Names of subelements to delete
subelement_names <- c("res_beta", "res_pcor")
l_comps_short <- list()

# Loop over each element of the list
for (i in seq_along(l_comps)) {
  # Get the names of the subelements for the current element
  current_subelement_names <- names(l_comps[[i]])
  # Determine which subelements to keep
  keep_indices <- !current_subelement_names %in% subelement_names
  # Use the subset operator to keep only the desired subelements
  l_comps_short[[i]] <- l_comps[[i]][keep_indices]
}

comps <- do.call(rbind.data.frame, l_comps_short)
# delete nonconverged attempts
# r_nonconv <- which(sapply(l_comps, function(x) length(x) == 0))
# fit_grid_conv <- fit_grid[-r_nonconv,]

df_comps <- cbind(comps, fit_grid)


```

Extract interesting cases
```{r}
# Find interesting cases with similar amount of observations
# nonsignificant 
# L1
# for rho 0.5, beta 1: 304
df_comps %>% 
  filter(sig_beta == 0 & sig_pcor  == 0) %>% 
  filter(fit_a != fit_b) %>% 
  left_join(n_obs, by = join_by(fit_a == subj_id)) %>% 
  left_join(n_obs, by = join_by(fit_b == subj_id), suffix = c("_a", "_b")) %>% 
  mutate(diff_n = abs(n_a - n_b)) %>% 
  arrange(diff_n)


# Both fully significant (both 2)
# L1
# for rho 0.5, beta 1: 100
df_comps %>% 
  filter(sig_beta > 1 & sig_pcor  > 1) %>% 
  filter(fit_a != fit_b) %>% 
  left_join(n_obs, by = join_by(fit_a == subj_id)) %>% 
  left_join(n_obs, by = join_by(fit_b == subj_id), suffix = c("_a", "_b")) %>% 
  mutate(diff_n = abs(n_a - n_b)) %>% 
  arrange(diff_n) 

# Both significant according to or rule
# L1
# for rho 0.5, beta 1: 442
df_comps %>% 
  filter(sig_beta > 0 & sig_pcor  > 0) %>% 
  filter(fit_a != fit_b) %>% 
  left_join(n_obs, by = join_by(fit_a == subj_id)) %>% 
  left_join(n_obs, by = join_by(fit_b == subj_id), suffix = c("_a", "_b")) %>% 
  mutate(diff_n = abs(n_a - n_b)) %>% 
  arrange(diff_n) 



# Only beta significant
# L1
# for rho 0.5, beta 1: 248
df_comps %>% 
  filter(sig_beta > 0 & sig_pcor == 0) %>% 
  filter(fit_a != fit_b) %>% 
  left_join(n_obs, by = join_by(fit_a == subj_id)) %>% 
  left_join(n_obs, by = join_by(fit_b == subj_id), suffix = c("_a", "_b")) %>% 
  mutate(diff_n = abs(n_a - n_b)) %>% 
  arrange(diff_n)

# Only pcor significant
# L1
# for rho 0.5, beta 1: 566
df_comps %>% 
  filter(sig_beta == 0 & sig_pcor > 0) %>% 
  filter(fit_a != fit_b) %>% 
  left_join(n_obs, by = join_by(fit_a == subj_id)) %>% 
  left_join(n_obs, by = join_by(fit_b == subj_id), suffix = c("_a", "_b")) %>% 
  mutate(diff_n = abs(n_a - n_b)) %>% 
  arrange(diff_n)


```







Visualize distributions of empirical differences
```{r}
df_comps %>% 
  filter(fit_a != fit_b) %>% 
  pivot_longer(cols = c("emp_beta", "emp_pcor"), names_to = "mat") %>% 
  ggplot(aes(x = value, fill = as.factor(mat))) +
  geom_density()
```




# Example A: Evidence for differences
27 and 3
```{r}
compare_var(l_fits[[8]], l_fits[[27]])
plot_net(l_fits[[8]])
plot_net(l_fits[[27]])


# Visualize differences
it_diff <- which(df_comps$fit_a == 8 & df_comps$fit_b == 27)
plot.compare_var(l_comps[[it_diff]])

```






# Example B: No evidence for differences
8 and 29
```{r}
compare_var(l_fits[[8]], l_fits[[29]])

plot_net(l_fits[[8]])
plot_net(l_fits[[29]])


# Visualize Differences
# Find iteration number
it_nodiff <- which(df_comps$fit_a == 8 & df_comps$fit_b == 29)

plot.compare_var(l_comps[[it_nodiff]])


```




# Plot Distances visualized as Network

Extract distances: 
```{r}
df_emp <- data.frame(emp_beta = rep(NA, 1600),
                     emp_pcor = rep(NA, 1600))
for(n in 1:length(l_comps)){
  df_emp[n,1] <- l_comps[[n]]$emp_beta
  df_emp[n,2] <- l_comps[[n]]$emp_pcor
}
# Combine with model information
df_emp <- cbind(df_emp, fit_grid)

# Filter irrelevant comparisons
df_emp <- df_emp %>% 
  filter(fit_a != fit_b)


# Correct data structure: 40 by 40 matrix
dist_beta_emp <- df_emp %>% 
  dplyr::select(emp_beta, fit_a, fit_b) %>% 
  reshape2::acast(., fit_a ~ fit_b, value.var = "emp_beta")


dist_pcor_emp <- df_emp %>% 
  dplyr::select(emp_pcor, fit_a, fit_b) %>% 
  reshape2::acast(., fit_a ~ fit_b, value.var = "emp_pcor")


```


Now visualize with qgraph
```{r}
# The shorter the distance, the larger the connection should be!
# Convert distance to similarity matrix
simil_beta_emp <- 1/mat_beta_emp
simil_pcor_emp <- 1/mat_pcor_emp

svg("emp_example_similarity_net.svg", width = 15, height = 12)
par(mfrow = c(1,2))
qgraph(simil_beta_emp, layout = "spring", title = "Beta")
qgraph(simil_pcor_emp, layout = "spring", title = "PCOR")
dev.off()


```


Also visualize with heatmap
```{r}
# Levels
id_lvls <- as.character(1:40)

# Get min and max similarities
min(simil_beta_emp, na.rm = TRUE)
min(simil_pcor_emp, na.rm = TRUE)
max(simil_beta_emp, na.rm = TRUE)
max(simil_pcor_emp, na.rm = TRUE)



p1 <- simil_beta_emp %>% 
  as.data.frame() %>% 
  rownames_to_column("id") %>% 
  pivot_longer(-c(id), names_to = "id2", values_to = "sim") %>% 
  mutate(id = fct_relevel(id, id_lvls),
         id2 = fct_relevel(id2, id_lvls)) %>% 
  ggplot(aes(x = id, y = id2, fill = sim))+
  geom_raster()+
  scale_fill_viridis_c(limits = c(0.1, 0.6))+
  labs(x = "ID",
       y = "ID",
       title = "Similarity Matrix Beta Weights",
       caption = "Frobenius Norm",
       fill = "Similarity")


p2 <- simil_pcor_emp %>% 
  as.data.frame() %>% 
  rownames_to_column("id") %>% 
  pivot_longer(-c(id), names_to = "id2", values_to = "sim") %>% 
  mutate(id = fct_relevel(id, id_lvls),
         id2 = fct_relevel(id2, id_lvls)) %>% 
  ggplot(aes(x = id, y = id2, fill = sim))+
  geom_raster()+
  scale_fill_viridis_c(limits = c(0.1, 0.6))+
  labs(x = "ID",
       y = "ID",
       title = "Similarity Matrix pcor Weights",
       caption = "Frobenius Norm",
       fill = "Similarity")

p <- cowplot::plot_grid(p1, p2)
ggsave("similarity_matrix_empirical_example.svg", p, device = "svg", path = here("figures/"), width = 15)



```




